{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import all necessary libraries ##\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "#########################\n",
    "\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.filtering.log.attributes import attributes_filter\n",
    "from pm4py.algo.filtering.log.variants import variants_filter\n",
    "from pm4py.statistics.traces.log import case_statistics\n",
    "from pm4py.objects.log.util import insert_classifier\n",
    "from pm4py.util import constants\n",
    "\n",
    "#########################\n",
    "\n",
    "import distance\n",
    "\n",
    "from similarity.levenshtein import Levenshtein\n",
    "levenshtein = Levenshtein()\n",
    "\n",
    "from similarity.damerau import Damerau\n",
    "damerau = Damerau()\n",
    "\n",
    "from pyjarowinkler import distance as jwdistance\n",
    "from similarity.jarowinkler import JaroWinkler\n",
    "jarowinkler = JaroWinkler()\n",
    "\n",
    "from similarity.weighted_levenshtein import WeightedLevenshtein\n",
    "from similarity.weighted_levenshtein import CharacterSubstitutionInterface\n",
    "import math\n",
    "from random import sample\n",
    "from random import seed\n",
    "class CharacterSubstitution(CharacterSubstitutionInterface):\n",
    "    def cost(self, c0, c1):\n",
    "        return math.inf # assign inifte weight to all substitutions\n",
    "levenshtein2 = WeightedLevenshtein(CharacterSubstitution())\n",
    "\n",
    "#########################\n",
    "\n",
    "import pomegranate as pom\n",
    "from sklearn import model_selection as ms\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distance:\n",
    "    \n",
    "    ### SETUP ###\n",
    "    \n",
    "    ## load dataset, generate mapping and generate strings\n",
    "    def __init__(self, log):\n",
    "        self.log = log\n",
    "        \n",
    "        self.strings = []\n",
    "        self.matrix = []\n",
    "        self.transl = {}\n",
    "        self.variant_to_Vindex = {}\n",
    "        self.index_to_variant = [] \n",
    "        #seed(1633048)\n",
    "        #self.log = sample(self.log, int(len(self.log)/10))\n",
    "        self.clear_caches()\n",
    "        \n",
    "        self.gen_trace_to_Tindex()\n",
    "        \n",
    "        self.gen_mapping()\n",
    "        self.gen_variant_strings()        \n",
    "    \n",
    "    def clear_caches(self):\n",
    "        self.Nk_res_dict = {} # N_k result cache\n",
    "    \n",
    "    ## generate mapping from activity to char\n",
    "    def gen_mapping(self):\n",
    "        ## generate mapping from activities to chars ##\n",
    "        # TODO read Activity Classifier for correct naming of activities\n",
    "        #activities = list(attributes_filter.get_attribute_values(self.log, \"concept:name\").keys())\n",
    "        activities = list(attributes_filter.get_attribute_values(self.log, \"customClassifier\").keys())\n",
    "        #activities2 = list(attributes_filter.get_attribute_values(self.log, \"lifecycle:transition\").keys())\n",
    "        #activities = [i + \"-\" + j for i, j in zip(activities2, activities2)]\n",
    "        for i, a in enumerate(activities):\n",
    "            self.transl[a] = chr(i+1)\n",
    "\n",
    "    def gen_trace_to_Tindex(self):\n",
    "        self.trace_to_Tindex = {}\n",
    "        for i, t in enumerate(self.log):\n",
    "            self.trace_to_Tindex[t] = i\n",
    "            \n",
    "            \n",
    "    ## generate strings for all variants\n",
    "    def gen_variant_strings(self):\n",
    "        self.variants = variants_filter.get_variants(self.log, parameters={variants_filter.Parameters.ACTIVITY_KEY: \"customClassifier\"}) # all variants as dictionary\n",
    "        variant_strings = list(self.variants.keys()) # variants as strings\n",
    "        self.variant_to_index = {} # dictionary to translate variant to index in list for later lookup of traces\n",
    "        \n",
    "        for i, v in enumerate(variant_strings):\n",
    "            string = \"\"\n",
    "            for e in v.split(\",\"):\n",
    "                string = string + self.transl[e] \n",
    "            \n",
    "            #self.strings.append(list_to_string(v.split(\",\")))\n",
    "            self.strings.append(string)\n",
    "            \n",
    "            self.variant_to_index[v] = i\n",
    "            self.index_to_variant.append(v)\n",
    "            \n",
    "        print(\"Number of variants: \" + str(len(self.strings)))\n",
    "    \n",
    "    ### CALCULATION ###\n",
    "    \n",
    "    ## calculate distance matrix\n",
    "    def calculate(self):\n",
    "        n = len(self.strings)\n",
    "        self.matrix = np.full((n, n), 0, dtype = np.uint8)\n",
    "\n",
    "        for i, x in enumerate(self.strings):\n",
    "            for j, y in enumerate(self.strings):\n",
    "                if j >= i: # only calculate upper right triangle of matrix\n",
    "                    #dist = distance.hamming(x, y)\n",
    "                    dist = levenshtein.distance(x, y)\n",
    "                    #dist = levenshtein2.distance(x, y)\n",
    "                    #dist = damerau.distance(x, y)\n",
    "                    #dist = (1- jarowinkler.similarity(x, y))*255\n",
    "                    #print(dist)\n",
    "                    self.matrix[i][j] = dist\n",
    "\n",
    "        # mirror upper right triangle of matrix by adding the transposition\n",
    "        self.matrix = self.matrix + self.matrix.T\n",
    "\n",
    "        return self.matrix\n",
    "    \n",
    "    ### RETRIEVAL ###\n",
    "    \n",
    "    ## translate trace to its corresponding matrix index\n",
    "    def trace_to_index(self, trace):\n",
    "        # convert trace to string tion of variant (concept:name separated by commas)\n",
    "        trace_string = \"\"\n",
    "        for e in trace:\n",
    "            #trace_string = trace_string + e[\"concept:name\"] + \",\"\n",
    "            trace_string = trace_string + e[\"customClassifier\"] + \",\"\n",
    "        trace_string = trace_string[:-1] # remove last comma\n",
    "\n",
    "        return self.variant_to_index[trace_string]\n",
    "    \n",
    "    ## translate matrix (variant) index to trace indices\n",
    "    def index_to_traces(self, i):\n",
    "        variant_string = self.index_to_variant[i]\n",
    "        traces = self.variants[variant_string] # retrieve traces from variant dictionary\n",
    "        filtered_variants = {variant_string: traces} # generate new variants dictionary with only one variant\n",
    "        \n",
    "        filtered_log = variants_filter.apply(self.log, filtered_variants, parameters={variants_filter.Parameters.ACTIVITY_KEY: \"customClassifier\"})\n",
    "        traces = []\n",
    "        for t in filtered_log:\n",
    "            traces.append(t)\n",
    "        \n",
    "        return traces\n",
    "        \n",
    "    \n",
    "    ## retrieve distance of two traces from matrix\n",
    "    def dist(self, t1, t2):\n",
    "        i1 = self.trace_to_index(t1)\n",
    "        i2 = self.trace_to_index(t2)\n",
    "        return self.matrix[i1][i2]\n",
    "    \n",
    "    # return traces of k nearest neighbors of A\n",
    "    def N_k(self, k, A):\n",
    "        A_variant_index = self.trace_to_index(A)\n",
    "        if A_variant_index in self.Nk_res_dict.keys(): # check result cache\n",
    "            #print(\"N_k cache hit\")\n",
    "            return self.Nk_res_dict[A_variant_index]\n",
    "        else:\n",
    "            idx_sort = np.argsort(self.matrix[A_variant_index]) # indices of neighbors in ascending distance\n",
    "\n",
    "            i = 0\n",
    "            N_k_traces = []\n",
    "            while len(N_k_traces) < k or self.matrix[A_variant_index][idx_sort[i-1]] == self.matrix[A_variant_index][idx_sort[i]]:\n",
    "                N_k_traces.extend(self.index_to_traces(idx_sort[i]))\n",
    "                if A in N_k_traces:\n",
    "                    N_k_traces.remove(A)\n",
    "                i = i + 1\n",
    "                if i == len(self.matrix): # if all traces have been added\n",
    "                    break\n",
    "                \n",
    "            \n",
    "            self.Nk_res_dict[A_variant_index] = N_k_traces\n",
    "            return N_k_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOF class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class LOF:\n",
    "    \n",
    "    def __init__(self, log):\n",
    "        self.dist = Distance(log)\n",
    "        self.dist.calculate()\n",
    "        self.clear_caches()\n",
    "    \n",
    "    def clear_caches(self):\n",
    "        self.dist.clear_caches()\n",
    "        \n",
    "        # result caches\n",
    "        self.kd_res_dict = {}\n",
    "        self.rd_res_dict = {}\n",
    "        self.lof_res_dict = {}\n",
    "        self.lrd_res_dict = {}\n",
    "    \n",
    "    \n",
    "    ## k-distance\n",
    "    def k_distance(self, k, A):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        if A_variant_index in self.kd_res_dict.keys(): # check result cache\n",
    "            #print(\"k_distance cache hit\")\n",
    "            return self.kd_res_dict[A_variant_index]\n",
    "        else:\n",
    "            N_k = self.dist.N_k(k, A)\n",
    "            k_variant_index = self.dist.trace_to_index(N_k[-1])\n",
    "            A_variant_index = self.dist.trace_to_index(A)\n",
    "\n",
    "            res = self.dist.matrix[A_variant_index][k_variant_index] # retrieve distance from k-th nearest neighbor (-1 to offset arraystart, +1 to not include trace itself)\n",
    "            self.kd_res_dict[A_variant_index] = res\n",
    "            return res\n",
    "        \n",
    "    ## reachability distance\n",
    "    def reachability_dist(self, k, A, B):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        B_variant_index = self.dist.trace_to_index(B)\n",
    "        if (A_variant_index, B_variant_index) in self.rd_res_dict.keys(): # check result cache\n",
    "            #print(\"rd cache hit\")\n",
    "            return self.rd_res_dict[(A_variant_index, B_variant_index)]\n",
    "        else:\n",
    "            res = max(self.k_distance(k, B), self.dist.matrix[A_variant_index][B_variant_index])\n",
    "            self.rd_res_dict[(A_variant_index, B_variant_index)] = res\n",
    "            return res\n",
    "    \n",
    "    ## local reachability density\n",
    "    def lrd(self, k, A):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        if A_variant_index in self.lrd_res_dict.keys(): # check result cache\n",
    "            #print(\"lrd cache hit\")\n",
    "            return self.lrd_res_dict[A_variant_index]\n",
    "        else:\n",
    "            \n",
    "            N_k = self.dist.N_k(k, A)            \n",
    "            sum = 0\n",
    "            for b in N_k:\n",
    "                   sum = sum + self.reachability_dist(k, A, b) # sum of rachability distances in k-Neighborhood\n",
    "            \n",
    "            res = 1 / (sum / len(N_k))\n",
    "            self.lrd_res_dict[A_variant_index] = res\n",
    "            return res\n",
    "        \n",
    "    def lof(self, k, A):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        if A_variant_index in self.lof_res_dict.keys(): # check result cache\n",
    "            #print(\"lof cache hit\")\n",
    "            return self.lof_res_dict[A_variant_index]\n",
    "        else:\n",
    "            \n",
    "            N_k = self.dist.N_k(k, A)\n",
    "            sum = 0\n",
    "            for b in N_k:\n",
    "                sum = sum + self.lrd(k, b)\n",
    "\n",
    "            res = sum / (len(N_k) * self.lrd(k, A))\n",
    "            self.lof_res_dict[A_variant_index] = res\n",
    "            return res\n",
    "    \n",
    "    def calculate(self, k):\n",
    "        res = np.array([])\n",
    "        \n",
    "        for a in self.dist.log:\n",
    "            res = np.append(res, self.lof(k, a))\n",
    "            \n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec46234425064917b7b0af731fb40b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n"
     ]
    }
   ],
   "source": [
    "path = \"Datasets/BPIC20_sample.xes\"\n",
    "log = xes_importer.apply(path)\n",
    "\n",
    "# generate custom activity classifier\n",
    "try:\n",
    "    \n",
    "    #log, activity_key = insert_classifier.insert_activity_classifier_attribute(self.log, \"Activity classifier\")\n",
    "    for trace in log:\n",
    "        for event in trace:\n",
    "            custom_classifier = \"\"\n",
    "            for activity_classifier in log.classifiers[\"Activity classifier\"]:\n",
    "                custom_classifier = custom_classifier + event[activity_classifier] + \"+\"\n",
    "            custom_classifier = custom_classifier[:-1]\n",
    "            event[\"customClassifier\"] = custom_classifier\n",
    "except:\n",
    "    print(\"foo\")\n",
    "    for trace in log:\n",
    "        for event in trace:\n",
    "            event[\"customClassifier\"] = event[\"concept:name\"]\n",
    "\n",
    "# generate index attribute for each event (later used to fiter)\n",
    "for trace in log:\n",
    "    for i, event in enumerate(trace):\n",
    "        event[\"index\"] = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LOFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-03 09:32:13.587470\n",
      "max trace length: 78\n",
      "l: 1\n",
      "Number of variants: 3\n",
      "l: 2\n",
      "Number of variants: 11\n",
      "l: 3\n",
      "Number of variants: 25\n",
      "l: 4\n",
      "Number of variants: 47\n",
      "l: 5\n",
      "Number of variants: 82\n",
      "l: 6\n",
      "Number of variants: 120\n",
      "l: 7\n",
      "Number of variants: 165\n",
      "l: 8\n",
      "Number of variants: 202\n",
      "l: 9\n",
      "Number of variants: 220\n",
      "l: 10\n",
      "Number of variants: 232\n",
      "l: 11\n",
      "Number of variants: 251\n",
      "l: 12\n",
      "Number of variants: 264\n",
      "l: 13\n",
      "Number of variants: 271\n",
      "l: 14\n",
      "Number of variants: 275\n",
      "l: 15\n",
      "Number of variants: 276\n",
      "l: 16\n",
      "Number of variants: 277\n",
      "l: 17\n",
      "Number of variants: 279\n",
      "l: 18\n",
      "Number of variants: 279\n",
      "l: 19\n",
      "Number of variants: 279\n",
      "l: 20\n",
      "Number of variants: 279\n",
      "l: 21\n",
      "Number of variants: 279\n",
      "l: 22\n",
      "Number of variants: 279\n",
      "l: 23\n",
      "Number of variants: 279\n",
      "l: 24\n",
      "Number of variants: 279\n",
      "l: 25\n",
      "Number of variants: 279\n",
      "l: 26\n",
      "Number of variants: 279\n",
      "l: 27\n",
      "Number of variants: 279\n",
      "l: 28\n",
      "Number of variants: 279\n",
      "l: 29\n",
      "Number of variants: 279\n",
      "l: 30\n",
      "Number of variants: 279\n",
      "l: 31\n",
      "Number of variants: 279\n",
      "l: 32\n",
      "Number of variants: 279\n",
      "l: 33\n",
      "Number of variants: 279\n",
      "l: 34\n",
      "Number of variants: 279\n",
      "l: 35\n",
      "Number of variants: 279\n",
      "l: 36\n",
      "Number of variants: 279\n",
      "l: 37\n",
      "Number of variants: 279\n",
      "l: 38\n",
      "Number of variants: 279\n",
      "l: 39\n",
      "Number of variants: 279\n",
      "l: 40\n",
      "Number of variants: 279\n",
      "l: 41\n",
      "Number of variants: 279\n",
      "l: 42\n",
      "Number of variants: 279\n",
      "l: 43\n",
      "Number of variants: 279\n",
      "l: 44\n",
      "Number of variants: 279\n",
      "l: 45\n",
      "Number of variants: 279\n",
      "l: 46\n",
      "Number of variants: 279\n",
      "l: 47\n",
      "Number of variants: 279\n",
      "l: 48\n",
      "Number of variants: 279\n",
      "l: 49\n",
      "Number of variants: 279\n",
      "l: 50\n",
      "Number of variants: 279\n",
      "l: 51\n",
      "Number of variants: 279\n",
      "l: 52\n",
      "Number of variants: 279\n",
      "l: 53\n",
      "Number of variants: 279\n",
      "l: 54\n",
      "Number of variants: 279\n",
      "l: 55\n",
      "Number of variants: 279\n",
      "l: 56\n",
      "Number of variants: 279\n",
      "l: 57\n",
      "Number of variants: 279\n",
      "l: 58\n",
      "Number of variants: 279\n",
      "l: 59\n",
      "Number of variants: 279\n",
      "l: 60\n",
      "Number of variants: 279\n",
      "l: 61\n",
      "Number of variants: 279\n",
      "l: 62\n",
      "Number of variants: 279\n",
      "l: 63\n",
      "Number of variants: 279\n",
      "l: 64\n",
      "Number of variants: 279\n",
      "l: 65\n",
      "Number of variants: 279\n",
      "l: 66\n",
      "Number of variants: 279\n",
      "l: 67\n",
      "Number of variants: 279\n",
      "l: 68\n",
      "Number of variants: 279\n",
      "l: 69\n",
      "Number of variants: 279\n",
      "l: 70\n",
      "Number of variants: 279\n",
      "l: 71\n",
      "Number of variants: 279\n",
      "l: 72\n",
      "Number of variants: 279\n",
      "l: 73\n",
      "Number of variants: 279\n",
      "l: 74\n",
      "Number of variants: 279\n",
      "l: 75\n",
      "Number of variants: 279\n",
      "l: 76\n",
      "Number of variants: 279\n",
      "l: 77\n",
      "Number of variants: 279\n",
      "l: 78\n",
      "Number of variants: 279\n",
      "1:58:08.867138\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(start)\n",
    "\n",
    "# find length of longest trace\n",
    "trace_len = [len(i) for i in log]\n",
    "max_trace_len = max(trace_len)\n",
    "print(\"max trace length: \" + str(max_trace_len))\n",
    "\n",
    "res = []\n",
    "res_dict = {}\n",
    "\n",
    "for l in range(0, max_trace_len): # iterate from 1 to length of longest trace\n",
    "    print(\"l: \" + str(l+1))\n",
    "    # filter events by attribute \"index\". only events with index between 0 and l are kept\n",
    "    log_tmp = attributes_filter.apply_numeric_events(log, 0, l, \n",
    "                                                     parameters={constants.PARAMETER_CONSTANT_ATTRIBUTE_KEY: \"index\"})\n",
    "    \n",
    "    \n",
    "    # run LOF calculation on filtered log\n",
    "    lof = LOF(log_tmp)\n",
    "\n",
    "    \n",
    "    \n",
    "    k = len(max(lof.dist.variants.values(), key=len)) + 1 # no. traces in largest variant + 1\n",
    "    res_tmp = lof.calculate(k)\n",
    "    res.append(res_tmp)\n",
    "    \n",
    "end = datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mirror results and rotate by 270 degrees\n",
    "res_rot = np.rot90(res[::-1], 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"res_BPIC20_sample.csv\", res_rot, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rot = np.genfromtxt(\"res_BPIC20_sample.csv\", delimiter=\",\")\n",
    "res = np.rot90(res_rot)\n",
    "res = res[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cutoffs for anomaly at each length\n",
    "cutoffs95 = []\n",
    "cutoffs85 = []\n",
    "cutoffs50 = []\n",
    "for l in range(len(res)):\n",
    "    r = []\n",
    "    for t in range(len(res_rot)):\n",
    "        if len(log[t]) >= l + 1:\n",
    "              r.append(res[l][t])        \n",
    "    cutoffs95.append(np.percentile(r, 95))\n",
    "    cutoffs85.append(np.percentile(r, 85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify traces at each point\n",
    "classification = [None] * len(res_rot)\n",
    "\n",
    "for j, trace_res in enumerate(res_rot):\n",
    "    classification_trace = [None] * len(log[j])\n",
    "    for i, r in enumerate(trace_res):\n",
    "        if i < len(log[j]):\n",
    "            if r > cutoffs95[i]:\n",
    "                classification_trace[i] = \"anomaly\"\n",
    "            elif r > cutoffs85[i]:\n",
    "                classification_trace[i] = \"mid\"\n",
    "            else:\n",
    "                classification_trace[i] = \"no anomaly\"\n",
    "    classification[j] = classification_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.9999851663959534,\n",
       " 1.7846462558763947,\n",
       " 1.6995115670119556,\n",
       " 1.9254848067526895,\n",
       " 2.3863126958810588,\n",
       " 2.578785954722325,\n",
       " 2.579785150540873,\n",
       " 1.8249994703996923,\n",
       " 2.8161280554114505,\n",
       " 3.2551044486941128,\n",
       " 3.750669247888859,\n",
       " 4.25367036936058,\n",
       " 4.567329330758997,\n",
       " 4.931840294609747,\n",
       " 5.236818274369675,\n",
       " 5.550449069584049,\n",
       " 5.703340438531346,\n",
       " 5.72635855362968,\n",
       " 5.5489901844574785,\n",
       " 3.9794586243601726,\n",
       " 3.988238056965276,\n",
       " 4.00746511749055,\n",
       " 4.162935589196695,\n",
       " 4.410712698477326,\n",
       " 4.648154460269511,\n",
       " 4.927434352539751,\n",
       " 5.105893879838723,\n",
       " 3.795598588248474,\n",
       " 3.720492446358056,\n",
       " 3.5925626760950715,\n",
       " 4.05161356460214,\n",
       " 4.289344022096785,\n",
       " 4.255352229664105,\n",
       " 5.213922463022161,\n",
       " 5.153837986377455,\n",
       " 5.4590226172660765,\n",
       " 5.676680516619111,\n",
       " 5.880895708099823,\n",
       " 6.6595641956532425,\n",
       " 6.8687014779477895,\n",
       " 7.597579844929374,\n",
       " 7.645948987517956,\n",
       " 7.885615256239711,\n",
       " 8.065957150106657,\n",
       " 8.253343523115229,\n",
       " 8.458024223250293,\n",
       " 8.69660979382343,\n",
       " 9.482952639511176,\n",
       " 4.767246384480741,\n",
       " 4.862602724215162,\n",
       " 4.9855275805543835,\n",
       " 5.107364606306531,\n",
       " 5.228113801471604,\n",
       " 5.3499508272237515,\n",
       " 5.472875683562973,\n",
       " 5.2779284791681444,\n",
       " 5.38855110681722,\n",
       " 5.501632015080719,\n",
       " 5.618400344265855,\n",
       " 5.736397813758202,\n",
       " 5.855624423557763,\n",
       " 5.976080173664535,\n",
       " 6.095306783464094,\n",
       " 6.213304252956442,\n",
       " 6.330072582141578,\n",
       " 6.440695209790654,\n",
       " 6.561150959897425,\n",
       " 6.6607113247815946,\n",
       " 6.778708794273944,\n",
       " 6.8967062637662915,\n",
       " 7.092789909261123,\n",
       " 7.211956406392527,\n",
       " 7.372558072224435,\n",
       " 7.494631952102057,\n",
       " 7.592056298542851,\n",
       " 7.421943318331719,\n",
       " 7.32902247259468]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoffs85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"res.csv\", res_rot, delimiter=\",\", fmt='%1.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8739667081870682\n",
      "0.09500622806024232\n",
      "0.03102706375268939\n"
     ]
    }
   ],
   "source": [
    "na = 0\n",
    "a = 0\n",
    "m = 0\n",
    "\n",
    "for t in classification:\n",
    "    for c in t:\n",
    "        if c == \"no anomaly\":\n",
    "            na = na+1\n",
    "        elif c == \"anomaly\":\n",
    "            a = a+1\n",
    "        elif c == \"mid\":\n",
    "            m = m+1\n",
    "t = na + a + m\n",
    "print(na/t)\n",
    "print(m/t)\n",
    "print(a/t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6660"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = []\n",
    "transl = {}\n",
    "## generate mapping from activities to chars ##\n",
    "activities = list(attributes_filter.get_attribute_values(log, \"customClassifier\").keys())\n",
    "for i, a in enumerate(activities):\n",
    "    transl[a] = chr(i+1)\n",
    "    \n",
    "for trace in log:\n",
    "    tlist = []\n",
    "    for i, event in enumerate(trace):\n",
    "        tlist.append(event[\"customClassifier\"])\n",
    "    lists.append(tlist)\n",
    "\n",
    "random.seed(1633048)\n",
    "\n",
    "# split data into training and test\n",
    "lists_train, lists_test, is_anomaly_train, is_anomaly_test = ms.train_test_split(lists, classification, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.44659377628259"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(len, lists_train))/float(len(lists_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model\n",
    "- Discrete obersvations\n",
    "- 3 states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pom.HiddenMarkovModel.from_samples(\n",
    "    pom.DiscreteDistribution, \n",
    "    n_components=3,\n",
    "    X=lists_train, \n",
    "    labels=is_anomaly_train,\n",
    "    state_names=[\"no anomaly\", \"mid\", \"anomaly\"],\n",
    "    algorithm=\"labeled\")\n",
    "model.bake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : {\n",
       "         \"class\" : \"Distribution\",\n",
       "         \"dtype\" : \"numpy.str_\",\n",
       "         \"name\" : \"DiscreteDistribution\",\n",
       "         \"parameters\" : [\n",
       "             {\n",
       "                 \"Declaration APPROVED by ADMINISTRATION\" : 0.08530805687203792,\n",
       "                 \"Declaration APPROVED by BUDGET OWNER\" : 0.009478672985781991,\n",
       "                 \"Declaration APPROVED by PRE_APPROVER\" : 0.014218009478672985,\n",
       "                 \"Declaration APPROVED by SUPERVISOR\" : 0.004739336492890996,\n",
       "                 \"Declaration FINAL_APPROVED by DIRECTOR\" : 0.0,\n",
       "                 \"Declaration FINAL_APPROVED by SUPERVISOR\" : 0.08056872037914692,\n",
       "                 \"Declaration REJECTED by ADMINISTRATION\" : 0.004739336492890996,\n",
       "                 \"Declaration REJECTED by BUDGET OWNER\" : 0.0,\n",
       "                 \"Declaration REJECTED by DIRECTOR\" : 0.004739336492890996,\n",
       "                 \"Declaration REJECTED by EMPLOYEE\" : 0.009478672985781991,\n",
       "                 \"Declaration REJECTED by MISSING\" : 0.004739336492890996,\n",
       "                 \"Declaration REJECTED by PRE_APPROVER\" : 0.0,\n",
       "                 \"Declaration REJECTED by SUPERVISOR\" : 0.0,\n",
       "                 \"Declaration SAVED by EMPLOYEE\" : 0.0,\n",
       "                 \"Declaration SUBMITTED by EMPLOYEE\" : 0.04265402843601896,\n",
       "                 \"End trip\" : 0.03317535545023697,\n",
       "                 \"Payment Handled\" : 0.12322274881516587,\n",
       "                 \"Permit APPROVED by ADMINISTRATION\" : 0.018957345971563982,\n",
       "                 \"Permit APPROVED by BUDGET OWNER\" : 0.014218009478672985,\n",
       "                 \"Permit APPROVED by PRE_APPROVER\" : 0.004739336492890996,\n",
       "                 \"Permit APPROVED by SUPERVISOR\" : 0.014218009478672985,\n",
       "                 \"Permit FINAL_APPROVED by DIRECTOR\" : 0.0,\n",
       "                 \"Permit FINAL_APPROVED by SUPERVISOR\" : 0.04739336492890995,\n",
       "                 \"Permit REJECTED by ADMINISTRATION\" : 0.009478672985781991,\n",
       "                 \"Permit REJECTED by BUDGET OWNER\" : 0.004739336492890996,\n",
       "                 \"Permit REJECTED by EMPLOYEE\" : 0.009478672985781991,\n",
       "                 \"Permit REJECTED by MISSING\" : 0.0,\n",
       "                 \"Permit REJECTED by PRE_APPROVER\" : 0.0,\n",
       "                 \"Permit REJECTED by SUPERVISOR\" : 0.004739336492890996,\n",
       "                 \"Permit SAVED by EMPLOYEE\" : 0.0,\n",
       "                 \"Permit SUBMITTED by EMPLOYEE\" : 0.018957345971563982,\n",
       "                 \"Request For Payment APPROVED by ADMINISTRATION\" : 0.037914691943127965,\n",
       "                 \"Request For Payment APPROVED by BUDGET OWNER\" : 0.009478672985781991,\n",
       "                 \"Request For Payment APPROVED by PRE_APPROVER\" : 0.02843601895734597,\n",
       "                 \"Request For Payment APPROVED by SUPERVISOR\" : 0.0,\n",
       "                 \"Request For Payment FINAL_APPROVED by DIRECTOR\" : 0.0,\n",
       "                 \"Request For Payment FINAL_APPROVED by SUPERVISOR\" : 0.06635071090047394,\n",
       "                 \"Request For Payment REJECTED by ADMINISTRATION\" : 0.009478672985781991,\n",
       "                 \"Request For Payment REJECTED by EMPLOYEE\" : 0.014218009478672985,\n",
       "                 \"Request For Payment REJECTED by MISSING\" : 0.0,\n",
       "                 \"Request For Payment SAVED by EMPLOYEE\" : 0.0,\n",
       "                 \"Request For Payment SUBMITTED by EMPLOYEE\" : 0.03317535545023697,\n",
       "                 \"Request Payment\" : 0.1848341232227488,\n",
       "                 \"Send Reminder\" : 0.009478672985781991,\n",
       "                 \"Start trip\" : 0.04265402843601896\n",
       "             }\n",
       "         ],\n",
       "         \"frozen\" : false\n",
       "     },\n",
       "     \"name\" : \"anomaly\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : {\n",
       "         \"class\" : \"Distribution\",\n",
       "         \"dtype\" : \"numpy.str_\",\n",
       "         \"name\" : \"DiscreteDistribution\",\n",
       "         \"parameters\" : [\n",
       "             {\n",
       "                 \"Declaration APPROVED by ADMINISTRATION\" : 0.029921259842519685,\n",
       "                 \"Declaration APPROVED by BUDGET OWNER\" : 0.0031496062992125984,\n",
       "                 \"Declaration APPROVED by PRE_APPROVER\" : 0.006299212598425197,\n",
       "                 \"Declaration APPROVED by SUPERVISOR\" : 0.009448818897637795,\n",
       "                 \"Declaration FINAL_APPROVED by DIRECTOR\" : 0.011023622047244094,\n",
       "                 \"Declaration FINAL_APPROVED by SUPERVISOR\" : 0.04251968503937008,\n",
       "                 \"Declaration REJECTED by ADMINISTRATION\" : 0.004724409448818898,\n",
       "                 \"Declaration REJECTED by BUDGET OWNER\" : 0.0,\n",
       "                 \"Declaration REJECTED by DIRECTOR\" : 0.0,\n",
       "                 \"Declaration REJECTED by EMPLOYEE\" : 0.004724409448818898,\n",
       "                 \"Declaration REJECTED by MISSING\" : 0.006299212598425197,\n",
       "                 \"Declaration REJECTED by PRE_APPROVER\" : 0.0015748031496062992,\n",
       "                 \"Declaration REJECTED by SUPERVISOR\" : 0.0031496062992125984,\n",
       "                 \"Declaration SAVED by EMPLOYEE\" : 0.0,\n",
       "                 \"Declaration SUBMITTED by EMPLOYEE\" : 0.05826771653543307,\n",
       "                 \"End trip\" : 0.08503937007874016,\n",
       "                 \"Payment Handled\" : 0.07716535433070866,\n",
       "                 \"Permit APPROVED by ADMINISTRATION\" : 0.05669291338582677,\n",
       "                 \"Permit APPROVED by BUDGET OWNER\" : 0.02047244094488189,\n",
       "                 \"Permit APPROVED by PRE_APPROVER\" : 0.0031496062992125984,\n",
       "                 \"Permit APPROVED by SUPERVISOR\" : 0.01889763779527559,\n",
       "                 \"Permit FINAL_APPROVED by DIRECTOR\" : 0.03307086614173228,\n",
       "                 \"Permit FINAL_APPROVED by SUPERVISOR\" : 0.06299212598425197,\n",
       "                 \"Permit REJECTED by ADMINISTRATION\" : 0.011023622047244094,\n",
       "                 \"Permit REJECTED by BUDGET OWNER\" : 0.0015748031496062992,\n",
       "                 \"Permit REJECTED by EMPLOYEE\" : 0.026771653543307086,\n",
       "                 \"Permit REJECTED by MISSING\" : 0.0015748031496062992,\n",
       "                 \"Permit REJECTED by PRE_APPROVER\" : 0.0015748031496062992,\n",
       "                 \"Permit REJECTED by SUPERVISOR\" : 0.0,\n",
       "                 \"Permit SAVED by EMPLOYEE\" : 0.004724409448818898,\n",
       "                 \"Permit SUBMITTED by EMPLOYEE\" : 0.09606299212598425,\n",
       "                 \"Request For Payment APPROVED by ADMINISTRATION\" : 0.02204724409448819,\n",
       "                 \"Request For Payment APPROVED by BUDGET OWNER\" : 0.015748031496062992,\n",
       "                 \"Request For Payment APPROVED by PRE_APPROVER\" : 0.0,\n",
       "                 \"Request For Payment APPROVED by SUPERVISOR\" : 0.0,\n",
       "                 \"Request For Payment FINAL_APPROVED by DIRECTOR\" : 0.004724409448818898,\n",
       "                 \"Request For Payment FINAL_APPROVED by SUPERVISOR\" : 0.029921259842519685,\n",
       "                 \"Request For Payment REJECTED by ADMINISTRATION\" : 0.0031496062992125984,\n",
       "                 \"Request For Payment REJECTED by EMPLOYEE\" : 0.004724409448818898,\n",
       "                 \"Request For Payment REJECTED by MISSING\" : 0.0015748031496062992,\n",
       "                 \"Request For Payment SAVED by EMPLOYEE\" : 0.0015748031496062992,\n",
       "                 \"Request For Payment SUBMITTED by EMPLOYEE\" : 0.04409448818897638,\n",
       "                 \"Request Payment\" : 0.07086614173228346,\n",
       "                 \"Send Reminder\" : 0.0015748031496062992,\n",
       "                 \"Start trip\" : 0.11811023622047244\n",
       "             }\n",
       "         ],\n",
       "         \"frozen\" : false\n",
       "     },\n",
       "     \"name\" : \"mid\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : {\n",
       "         \"class\" : \"Distribution\",\n",
       "         \"dtype\" : \"numpy.str_\",\n",
       "         \"name\" : \"DiscreteDistribution\",\n",
       "         \"parameters\" : [\n",
       "             {\n",
       "                 \"Declaration APPROVED by ADMINISTRATION\" : 0.06485911749069644,\n",
       "                 \"Declaration APPROVED by BUDGET OWNER\" : 0.025695552011341487,\n",
       "                 \"Declaration APPROVED by PRE_APPROVER\" : 0.006379585326953748,\n",
       "                 \"Declaration APPROVED by SUPERVISOR\" : 0.001063264221158958,\n",
       "                 \"Declaration FINAL_APPROVED by DIRECTOR\" : 0.000886053517632465,\n",
       "                 \"Declaration FINAL_APPROVED by SUPERVISOR\" : 0.07371965266702109,\n",
       "                 \"Declaration REJECTED by ADMINISTRATION\" : 0.021619705830232146,\n",
       "                 \"Declaration REJECTED by BUDGET OWNER\" : 0.001240474924685451,\n",
       "                 \"Declaration REJECTED by DIRECTOR\" : 0.0,\n",
       "                 \"Declaration REJECTED by EMPLOYEE\" : 0.025341130604288498,\n",
       "                 \"Declaration REJECTED by MISSING\" : 0.000886053517632465,\n",
       "                 \"Declaration REJECTED by PRE_APPROVER\" : 0.000886053517632465,\n",
       "                 \"Declaration REJECTED by SUPERVISOR\" : 0.002303739145844409,\n",
       "                 \"Declaration SAVED by EMPLOYEE\" : 0.000354421407052986,\n",
       "                 \"Declaration SUBMITTED by EMPLOYEE\" : 0.10295941874889243,\n",
       "                 \"End trip\" : 0.08311181995392522,\n",
       "                 \"Payment Handled\" : 0.01648059542796385,\n",
       "                 \"Permit APPROVED by ADMINISTRATION\" : 0.07531454899875953,\n",
       "                 \"Permit APPROVED by BUDGET OWNER\" : 0.02835371256423888,\n",
       "                 \"Permit APPROVED by PRE_APPROVER\" : 0.007442849548112706,\n",
       "                 \"Permit APPROVED by SUPERVISOR\" : 0.006379585326953748,\n",
       "                 \"Permit FINAL_APPROVED by DIRECTOR\" : 0.00531632110579479,\n",
       "                 \"Permit FINAL_APPROVED by SUPERVISOR\" : 0.08009923799397484,\n",
       "                 \"Permit REJECTED by ADMINISTRATION\" : 0.000177210703526493,\n",
       "                 \"Permit REJECTED by BUDGET OWNER\" : 0.001594896331738437,\n",
       "                 \"Permit REJECTED by EMPLOYEE\" : 0.001594896331738437,\n",
       "                 \"Permit REJECTED by MISSING\" : 0.0,\n",
       "                 \"Permit REJECTED by PRE_APPROVER\" : 0.0,\n",
       "                 \"Permit REJECTED by SUPERVISOR\" : 0.001063264221158958,\n",
       "                 \"Permit SAVED by EMPLOYEE\" : 0.0,\n",
       "                 \"Permit SUBMITTED by EMPLOYEE\" : 0.09197235513024987,\n",
       "                 \"Request For Payment APPROVED by ADMINISTRATION\" : 0.019847598794967215,\n",
       "                 \"Request For Payment APPROVED by BUDGET OWNER\" : 0.009214956583377636,\n",
       "                 \"Request For Payment APPROVED by PRE_APPROVER\" : 0.000354421407052986,\n",
       "                 \"Request For Payment APPROVED by SUPERVISOR\" : 0.000531632110579479,\n",
       "                 \"Request For Payment FINAL_APPROVED by DIRECTOR\" : 0.0,\n",
       "                 \"Request For Payment FINAL_APPROVED by SUPERVISOR\" : 0.020379230905546695,\n",
       "                 \"Request For Payment REJECTED by ADMINISTRATION\" : 0.00177210703526493,\n",
       "                 \"Request For Payment REJECTED by EMPLOYEE\" : 0.001417685628211944,\n",
       "                 \"Request For Payment REJECTED by MISSING\" : 0.000177210703526493,\n",
       "                 \"Request For Payment SAVED by EMPLOYEE\" : 0.000177210703526493,\n",
       "                 \"Request For Payment SUBMITTED by EMPLOYEE\" : 0.023214602161970584,\n",
       "                 \"Request Payment\" : 0.09321283005493532,\n",
       "                 \"Send Reminder\" : 0.017543859649122806,\n",
       "                 \"Start trip\" : 0.08506113769271664\n",
       "             }\n",
       "         ],\n",
       "         \"frozen\" : false\n",
       "     },\n",
       "     \"name\" : \"no anomaly\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : null,\n",
       "     \"name\" : \"None-start\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : null,\n",
       "     \"name\" : \"None-end\",\n",
       "     \"weight\" : 1.0\n",
       " }]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49748744, 0.21105528, 0.29145729, 0.        , 0.        ],\n",
       "       [0.14715719, 0.53344482, 0.31939799, 0.        , 0.        ],\n",
       "       [0.00421644, 0.04813774, 0.94764582, 0.        , 0.        ],\n",
       "       [0.33333333, 0.33333333, 0.33333333, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dense_transition_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using last event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na_na: 93.6%\n",
      "na_m: 0.0%\n",
      "na_a:0.0%\n",
      "\n",
      "m_na: 6.0%\n",
      "m_m: 0.0%\n",
      "m_a: 0.0%\n",
      "\n",
      "a_na: 0.3%\n",
      "a_m: 0.3%\n",
      "a_a: 0.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "na_na = 0\n",
    "na_m = 0\n",
    "na_a = 0\n",
    "\n",
    "m_na = 0\n",
    "m_m = 0 \n",
    "m_a = 0\n",
    "\n",
    "a_na = 0\n",
    "a_m = 0\n",
    "a_a = 0\n",
    "\n",
    "for i, t in enumerate(lists_test):\n",
    "    prediction = model.predict(t)\n",
    "    prediction_last_name = model.states[prediction[-1]].name\n",
    "    if prediction_last_name == \"no anomaly\" and is_anomaly_test[i][-1] == \"no anomaly\" :\n",
    "        na_na = na_na + 1\n",
    "    elif prediction_last_name == \"mid\" and is_anomaly_test[i][-1] == \"no anomaly\" :\n",
    "        na_m = na_m + 1\n",
    "    elif prediction_last_name == \"anomaly\" and is_anomaly_test[i][-1] == \"no anomaly\" :\n",
    "        na_a = na_m + 1\n",
    "    \n",
    "    elif prediction_last_name == \"no anomaly\" and is_anomaly_test[i][-1] == \"mid\":\n",
    "        m_na = m_na + 1\n",
    "    elif prediction_last_name == \"mid\" and is_anomaly_test[i][-1] == \"mid\":\n",
    "        m_m = m_m + 1\n",
    "    elif prediction_last_name == \"anomaly\" and is_anomaly_test[i][-1] == \"mid\":\n",
    "        m_a = m_a + 1\n",
    "        \n",
    "    elif prediction_last_name == \"no anomaly\" and is_anomaly_test[i][-1] == \"anomaly\" :\n",
    "        a_na = a_na + 1\n",
    "    elif prediction_last_name == \"mid\" and is_anomaly_test[i][-1] == \"anomaly\" :\n",
    "        a_m = a_m + 1\n",
    "    elif prediction_last_name == \"anomaly\" and is_anomaly_test[i][-1] == \"anomaly\" :\n",
    "        a_a = a_a + 1\n",
    "\n",
    "\n",
    "total = len(is_anomaly_test)\n",
    "print(\"na_na: \" + str(round(na_na/total * 100, 1))+\"%\")\n",
    "print(\"na_m: \"+ str(round(na_m/total * 100, 1))+\"%\")\n",
    "print(\"na_a:\" + str(round(na_a/total * 100, 1))+\"%\")\n",
    "print()\n",
    "print(\"m_na: \" + str(round(m_na/total * 100, 1))+\"%\")\n",
    "print(\"m_m: \" + str(round(m_m/total * 100, 1))+\"%\")\n",
    "print(\"m_a: \" + str(round(m_a/total * 100, 1))+\"%\")\n",
    "print()\n",
    "print(\"a_na: \" + str(round(a_na/total * 100, 1))+\"%\")\n",
    "print(\"a_m: \" + str(round(a_na/total * 100, 1))+\"%\")\n",
    "print(\"a_a: \" + str(round(a_a/total * 100, 1))+\"%\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using all events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na_na: 66.4\n",
      "na_m: 12.7\n",
      "na_a:11.5\n",
      "\n",
      "m_na: 4.3\n",
      "m_m: 1.3\n",
      "m_a: 0.7\n",
      "\n",
      "a_na: 1.4\n",
      "a_m: 1.4\n",
      "a_a: 0.6\n",
      "\n",
      "err: 31.7\n"
     ]
    }
   ],
   "source": [
    "# average over all events\n",
    "na_na = 0\n",
    "na_m = 0\n",
    "na_a = 0\n",
    "\n",
    "m_na = 0\n",
    "m_m = 0 \n",
    "m_a = 0\n",
    "\n",
    "a_na = 0\n",
    "a_m = 0\n",
    "a_a = 0\n",
    "\n",
    "for i, t in enumerate(lists_test):\n",
    "    \n",
    "    prediction = model.predict(t)\n",
    "    \n",
    "    for j, p in enumerate(prediction):\n",
    "        p_name = model.states[p].name\n",
    "        if p_name == \"no anomaly\" and is_anomaly_test[i][-1] == \"no anomaly\" :\n",
    "            na_na = na_na + 1\n",
    "        elif  p_name == \"mid\" and is_anomaly_test[i][-1] == \"no anomaly\" :\n",
    "            na_m = na_m + 1\n",
    "        elif  p_name == \"anomaly\" and is_anomaly_test[i][-1] == \"no anomaly\" :\n",
    "            na_a = na_m + 1\n",
    "\n",
    "        elif  p_name == \"no anomaly\" and is_anomaly_test[i][-1] == \"mid\":\n",
    "            m_na = m_na + 1\n",
    "        elif  p_name == \"mid\" and is_anomaly_test[i][-1] == \"mid\":\n",
    "            m_m = m_m + 1\n",
    "        elif  p_name == \"anomaly\" and is_anomaly_test[i][-1] == \"mid\":\n",
    "            m_a = m_a + 1\n",
    "\n",
    "        elif  p_name == \"no anomaly\" and is_anomaly_test[i][-1] == \"anomaly\" :\n",
    "            a_na = a_na + 1\n",
    "        elif  p_name == \"mid\" and is_anomaly_test[i][-1] == \"anomaly\" :\n",
    "            a_m = a_m + 1\n",
    "        elif  p_name == \"anomaly\" and is_anomaly_test[i][-1] == \"anomaly\" :\n",
    "            a_a = a_a + 1\n",
    "\n",
    "\n",
    "total = na_na+na_m+na_a + m_na+m_m+m_a + a_na+a_m+a_a\n",
    "print(\"na_na: \" + str(round(na_na/total * 100, 1)))\n",
    "print(\"na_m: \"+ str(round(na_m/total * 100, 1)))\n",
    "print(\"na_a:\" + str(round(na_a/total * 100, 1)))\n",
    "print()\n",
    "print(\"m_na: \" + str(round(m_na/total * 100, 1)))\n",
    "print(\"m_m: \" + str(round(m_m/total * 100, 1)))\n",
    "print(\"m_a: \" + str(round(m_a/total * 100, 1)))\n",
    "print()\n",
    "print(\"a_na: \" + str(round(a_na/total * 100, 1)))\n",
    "print(\"a_m: \" + str(round(a_na/total * 100, 1)))\n",
    "print(\"a_a: \" + str(round(a_a/total * 100, 1)))\n",
    "print()\n",
    "print(\"err: \" + str(round((1 - (na_na+m_m+a_a) / total) * 100, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'68.3'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na_na\t77.5\n",
      "na_m\t9.7\n",
      "na_a\t4.4\n",
      "\n",
      "m_na\t5.5\n",
      "m_m\t1.7\n",
      "m_a\t0.6\n",
      "\n",
      "a_na\t0.9\n",
      "a_m\t0.9\n",
      "a_a\t0.3\n",
      "\n",
      "err\t20.8\n"
     ]
    }
   ],
   "source": [
    "# average over all traces\n",
    "na_na_list = []\n",
    "na_m_list = []\n",
    "na_a_list = []\n",
    "\n",
    "m_na_list = []\n",
    "m_m_list = []\n",
    "m_a_list = []\n",
    "\n",
    "a_na_list = []\n",
    "a_m_list = []\n",
    "a_a_list = []\n",
    "\n",
    "err_list = []\n",
    "\n",
    "for i, t in enumerate(lists_test):\n",
    "    na_na = 0\n",
    "    na_m = 0\n",
    "    na_a = 0\n",
    "\n",
    "    m_na = 0\n",
    "    m_m = 0 \n",
    "    m_a = 0\n",
    "\n",
    "    a_na = 0\n",
    "    a_m = 0\n",
    "    a_a = 0\n",
    "\n",
    "    prediction = model.predict(t)\n",
    "    \n",
    "    for j, p in enumerate(prediction):\n",
    "        p_name = model.states[p].name\n",
    "        if p_name == \"no anomaly\" and is_anomaly_test[i][-1] == \"no anomaly\" :\n",
    "            na_na = na_na + 1\n",
    "        elif  p_name == \"mid\" and is_anomaly_test[i][-1] == \"no anomaly\" :\n",
    "            na_m = na_m + 1\n",
    "        elif  p_name == \"anomaly\" and is_anomaly_test[i][-1] == \"no anomaly\" :\n",
    "            na_a = na_m + 1\n",
    "\n",
    "        elif  p_name == \"no anomaly\" and is_anomaly_test[i][-1] == \"mid\":\n",
    "            m_na = m_na + 1\n",
    "        elif  p_name == \"mid\" and is_anomaly_test[i][-1] == \"mid\":\n",
    "            m_m = m_m + 1\n",
    "        elif  p_name == \"anomaly\" and is_anomaly_test[i][-1] == \"mid\":\n",
    "            m_a = m_a + 1\n",
    "\n",
    "        elif  p_name == \"no anomaly\" and is_anomaly_test[i][-1] == \"anomaly\" :\n",
    "            a_na = a_na + 1\n",
    "        elif  p_name == \"mid\" and is_anomaly_test[i][-1] == \"anomaly\" :\n",
    "            a_m = a_m + 1\n",
    "        elif  p_name == \"anomaly\" and is_anomaly_test[i][-1] == \"anomaly\" :\n",
    "            a_a = a_a + 1\n",
    "\n",
    "        \n",
    "    na_na_list.append(na_na / len(prediction))\n",
    "    na_m_list.append(na_m / len(prediction))\n",
    "    na_a_list.append(na_a / len(prediction))\n",
    "    \n",
    "    m_na_list.append(m_na / len(prediction))\n",
    "    m_m_list.append(m_m / len(prediction))\n",
    "    m_a_list.append(m_a / len(prediction))\n",
    "    \n",
    "    a_na_list.append(a_na / len(prediction))\n",
    "    a_m_list.append(a_m / len(prediction))\n",
    "    a_a_list.append(a_a / len(prediction))\n",
    "    \n",
    "    err_list.append(1 - (na_na+m_m+a_a) / (na_na+na_m+na_a + m_na+m_m+m_a + a_na+a_m+a_a))\n",
    "        \n",
    "            \n",
    "print(\"na_na\\t\" + str(round(sum(na_na_list) / len(na_na_list) * 100, 1)))\n",
    "print(\"na_m\\t\" + str(round(sum(na_m_list) / len(na_m_list) * 100, 1)))\n",
    "print(\"na_a\\t\" + str(round(sum(na_a_list) / len(na_a_list) * 100, 1)))   \n",
    "print()\n",
    "print(\"m_na\\t\" + str(round(sum(m_na_list) / len(m_na_list) * 100, 1)))\n",
    "print(\"m_m\\t\" + str(round(sum(m_m_list) / len(m_m_list) * 100, 1)))\n",
    "print(\"m_a\\t\" + str(round(sum(m_a_list) / len(m_a_list) * 100, 1)))\n",
    "print()\n",
    "print(\"a_na\\t\" + str(round(sum(a_na_list) / len(a_na_list) * 100, 1)))\n",
    "print(\"a_m\\t\" + str(round(sum(a_m_list) / len(a_m_list) * 100, 1)))\n",
    "print(\"a_a\\t\" + str(round(sum(a_a_list) / len(a_a_list) * 100, 1)))\n",
    "print()\n",
    "print(\"err\\t\" + str(round(sum(err_list) / len(err_list) * 100, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
