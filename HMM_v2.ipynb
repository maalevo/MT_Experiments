{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import all necessary libraries ##\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "#########################\n",
    "\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.filtering.log.attributes import attributes_filter\n",
    "from pm4py.algo.filtering.log.variants import variants_filter\n",
    "from pm4py.statistics.traces.log import case_statistics\n",
    "from pm4py.objects.log.util import insert_classifier\n",
    "from pm4py.util import constants\n",
    "\n",
    "#########################\n",
    "\n",
    "import distance\n",
    "\n",
    "from similarity.levenshtein import Levenshtein\n",
    "levenshtein = Levenshtein()\n",
    "\n",
    "from similarity.damerau import Damerau\n",
    "damerau = Damerau()\n",
    "\n",
    "from pyjarowinkler import distance as jwdistance\n",
    "from similarity.jarowinkler import JaroWinkler\n",
    "jarowinkler = JaroWinkler()\n",
    "\n",
    "from similarity.weighted_levenshtein import WeightedLevenshtein\n",
    "from similarity.weighted_levenshtein import CharacterSubstitutionInterface\n",
    "import math\n",
    "from random import sample\n",
    "from random import seed\n",
    "class CharacterSubstitution(CharacterSubstitutionInterface):\n",
    "    def cost(self, c0, c1):\n",
    "        return math.inf # assign inifte weight to all substitutions\n",
    "levenshtein2 = WeightedLevenshtein(CharacterSubstitution())\n",
    "\n",
    "#########################\n",
    "\n",
    "import pomegranate as pom\n",
    "from sklearn import model_selection as ms\n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distance:\n",
    "    \n",
    "    ### SETUP ###\n",
    "    \n",
    "    ## load dataset, generate mapping and generate strings\n",
    "    def __init__(self, log):\n",
    "        self.log = log\n",
    "        \n",
    "        self.strings = []\n",
    "        self.matrix = []\n",
    "        self.transl = {}\n",
    "        self.variant_to_Vindex = {}\n",
    "        self.index_to_variant = [] \n",
    "        #seed(1633048)\n",
    "        #self.log = sample(self.log, int(len(self.log)/10))\n",
    "        self.clear_caches()\n",
    "        \n",
    "        self.gen_trace_to_Tindex()\n",
    "        \n",
    "        self.gen_mapping()\n",
    "        self.gen_variant_strings()        \n",
    "    \n",
    "    def clear_caches(self):\n",
    "        self.Nk_res_dict = {} # N_k result cache\n",
    "    \n",
    "    ## generate mapping from activity to char\n",
    "    def gen_mapping(self):\n",
    "        activities = list(attributes_filter.get_attribute_values(self.log, \"customClassifier\").keys())\n",
    "        for i, a in enumerate(activities):\n",
    "            self.transl[a] = chr(i+1)\n",
    "\n",
    "    def gen_trace_to_Tindex(self):\n",
    "        self.trace_to_Tindex = {}\n",
    "        for i, t in enumerate(self.log):\n",
    "            self.trace_to_Tindex[t] = i\n",
    "            \n",
    "            \n",
    "    ## generate strings for all variants\n",
    "    def gen_variant_strings(self):\n",
    "        self.variants = variants_filter.get_variants(self.log, parameters={variants_filter.Parameters.ACTIVITY_KEY: \"customClassifier\"}) # all variants as dictionary\n",
    "        variant_strings = list(self.variants.keys()) # variants as strings\n",
    "        self.variant_to_index = {} # dictionary to translate variant to index in list for later lookup of traces\n",
    "        \n",
    "        for i, v in enumerate(variant_strings):\n",
    "            string = \"\"\n",
    "            for e in v.split(\",\"):\n",
    "                string = string + self.transl[e] \n",
    "            \n",
    "            #self.strings.append(list_to_string(v.split(\",\")))\n",
    "            self.strings.append(string)\n",
    "            \n",
    "            self.variant_to_index[v] = i\n",
    "            self.index_to_variant.append(v)\n",
    "            \n",
    "        print(\"Number of variants: \" + str(len(self.strings)))\n",
    "    \n",
    "    ### CALCULATION ###\n",
    "    \n",
    "    ## calculate distance matrix\n",
    "    def calculate(self):\n",
    "        n = len(self.strings)\n",
    "        self.matrix = np.full((n, n), 0, dtype = np.uint8)\n",
    "\n",
    "        for i, x in enumerate(self.strings):\n",
    "            for j, y in enumerate(self.strings):\n",
    "                if j >= i: # only calculate upper right triangle of matrix\n",
    "                    #dist = distance.hamming(x, y)\n",
    "                    dist = levenshtein.distance(x, y)\n",
    "                    #dist = levenshtein2.distance(x, y)\n",
    "                    #dist = damerau.distance(x, y)\n",
    "                    #dist = (1- jarowinkler.similarity(x, y))*255\n",
    "                    #print(dist)\n",
    "                    self.matrix[i][j] = dist\n",
    "\n",
    "        # mirror upper right triangle of matrix by adding the transposition\n",
    "        self.matrix = self.matrix + self.matrix.T\n",
    "\n",
    "        return self.matrix\n",
    "    \n",
    "    ### RETRIEVAL ###\n",
    "    \n",
    "    ## translate trace to its corresponding matrix index\n",
    "    def trace_to_index(self, trace):\n",
    "        # convert trace to string tion of variant (concept:name separated by commas)\n",
    "        trace_string = \"\"\n",
    "        for e in trace:\n",
    "            #trace_string = trace_string + e[\"concept:name\"] + \",\"\n",
    "            trace_string = trace_string + e[\"customClassifier\"] + \",\"\n",
    "        trace_string = trace_string[:-1] # remove last comma\n",
    "\n",
    "        return self.variant_to_index[trace_string]\n",
    "    \n",
    "    ## translate matrix (variant) index to trace indices\n",
    "    def index_to_traces(self, i):\n",
    "        variant_string = self.index_to_variant[i]\n",
    "        traces = self.variants[variant_string] # retrieve traces from variant dictionary\n",
    "        filtered_variants = {variant_string: traces} # generate new variants dictionary with only one variant\n",
    "        \n",
    "        filtered_log = variants_filter.apply(self.log, filtered_variants, parameters={variants_filter.Parameters.ACTIVITY_KEY: \"customClassifier\"})\n",
    "        traces = []\n",
    "        for t in filtered_log:\n",
    "            traces.append(t)\n",
    "        \n",
    "        return traces\n",
    "        \n",
    "    \n",
    "    ## retrieve distance of two traces from matrix\n",
    "    def dist(self, t1, t2):\n",
    "        i1 = self.trace_to_index(t1)\n",
    "        i2 = self.trace_to_index(t2)\n",
    "        return self.matrix[i1][i2]\n",
    "    \n",
    "    # return traces of k nearest neighbors of A\n",
    "    def N_k(self, k, A):\n",
    "        A_variant_index = self.trace_to_index(A)\n",
    "        if A_variant_index in self.Nk_res_dict.keys(): # check result cache\n",
    "            #print(\"N_k cache hit\")\n",
    "            return self.Nk_res_dict[A_variant_index]\n",
    "        else:\n",
    "            idx_sort = np.argsort(self.matrix[A_variant_index]) # indices of neighbors in ascending distance\n",
    "\n",
    "            i = 0\n",
    "            N_k_traces = []\n",
    "            \n",
    "            while len(N_k_traces) < k or self.matrix[A_variant_index][idx_sort[i-1]] == self.matrix[A_variant_index][idx_sort[i]]:\n",
    "                N_k_traces.extend(self.index_to_traces(idx_sort[i]))\n",
    "                if A in N_k_traces:\n",
    "                    N_k_traces.remove(A)\n",
    "                i = i + 1\n",
    "                if i == len(self.matrix): # if all traces have been added\n",
    "                    break\n",
    "                \n",
    "            \n",
    "            self.Nk_res_dict[A_variant_index] = N_k_traces\n",
    "            return N_k_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOF class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LOF:\n",
    "    \n",
    "    def __init__(self, log):\n",
    "        self.dist = Distance(log)\n",
    "        self.dist.calculate()\n",
    "        self.clear_caches()\n",
    "    \n",
    "    def clear_caches(self):\n",
    "        self.dist.clear_caches()\n",
    "        \n",
    "        # result caches\n",
    "        self.kd_res_dict = {}\n",
    "        self.rd_res_dict = {}\n",
    "        self.lof_res_dict = {}\n",
    "        self.lrd_res_dict = {}\n",
    "    \n",
    "    \n",
    "    ## k-distance\n",
    "    def k_distance(self, k, A):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        if A_variant_index in self.kd_res_dict.keys(): # check result cache\n",
    "            #print(\"k_distance cache hit\")\n",
    "            return self.kd_res_dict[A_variant_index]\n",
    "        else:\n",
    "            N_k = self.dist.N_k(k, A)\n",
    "            k_variant_index = self.dist.trace_to_index(N_k[-1])\n",
    "            A_variant_index = self.dist.trace_to_index(A)\n",
    "\n",
    "            res = self.dist.matrix[A_variant_index][k_variant_index] # retrieve distance from k-th nearest neighbor (-1 to offset arraystart, +1 to not include trace itself)\n",
    "            self.kd_res_dict[A_variant_index] = res\n",
    "            return res\n",
    "        \n",
    "    ## reachability distance\n",
    "    def reachability_dist(self, k, A, B):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        B_variant_index = self.dist.trace_to_index(B)\n",
    "        if (A_variant_index, B_variant_index) in self.rd_res_dict.keys(): # check result cache\n",
    "            #print(\"rd cache hit\")\n",
    "            return self.rd_res_dict[(A_variant_index, B_variant_index)]\n",
    "        else:\n",
    "            res = max(self.k_distance(k, B), self.dist.matrix[A_variant_index][B_variant_index])\n",
    "            self.rd_res_dict[(A_variant_index, B_variant_index)] = res\n",
    "            return res\n",
    "    \n",
    "    ## local reachability density\n",
    "    def lrd(self, k, A):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        if A_variant_index in self.lrd_res_dict.keys(): # check result cache\n",
    "            #print(\"lrd cache hit\")\n",
    "            return self.lrd_res_dict[A_variant_index]\n",
    "        else:\n",
    "            \n",
    "            N_k = self.dist.N_k(k, A)            \n",
    "            sum = 0\n",
    "            for b in N_k:\n",
    "                   sum = sum + self.reachability_dist(k, A, b) # sum of rachability distances in k-Neighborhood\n",
    "            \n",
    "            res = 1 / (sum / len(N_k))\n",
    "            self.lrd_res_dict[A_variant_index] = res\n",
    "            return res\n",
    "        \n",
    "    def lof(self, k, A):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        if A_variant_index in self.lof_res_dict.keys(): # check result cache\n",
    "            #print(\"lof cache hit\")\n",
    "            return self.lof_res_dict[A_variant_index]\n",
    "        else:\n",
    "            \n",
    "            N_k = self.dist.N_k(k, A)\n",
    "            sum = 0\n",
    "            for b in N_k:\n",
    "                sum = sum + self.lrd(k, b)\n",
    "\n",
    "            res = sum / (len(N_k) * self.lrd(k, A))\n",
    "            self.lof_res_dict[A_variant_index] = res\n",
    "            return res\n",
    "    \n",
    "    def calculate(self, k):\n",
    "        res = np.array([])\n",
    "        \n",
    "        for a in self.dist.log:\n",
    "            res = np.append(res, self.lof(k, a))\n",
    "            \n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de5aafa9d26412bb77c9805daf79af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n"
     ]
    }
   ],
   "source": [
    "path = \"Datasets/BPIC20_sample.xes\"\n",
    "log = xes_importer.apply(path)\n",
    "\n",
    "# generate custom activity classifier\n",
    "try:\n",
    "    \n",
    "    #log, activity_key = insert_classifier.insert_activity_classifier_attribute(self.log, \"Activity classifier\")\n",
    "    for trace in log:\n",
    "        for event in trace:\n",
    "            custom_classifier = \"\"\n",
    "            #loop through all attributes which classify the activity\n",
    "            for activity_classifier in log.classifiers[\"Activity classifier\"]:\n",
    "                #generate new attribute combining all classifying attributes\n",
    "                custom_classifier = custom_classifier + event[activity_classifier] + \"+\"\n",
    "            custom_classifier = custom_classifier[:-1]\n",
    "            event[\"customClassifier\"] = custom_classifier\n",
    "except: \n",
    "    print(\"foo\")\n",
    "    for trace in log:\n",
    "        for event in trace:\n",
    "            event[\"customClassifier\"] = event[\"concept:name\"]\n",
    "\n",
    "# generate index attribute for each event (later used to fiter)\n",
    "for trace in log:\n",
    "    for i, event in enumerate(trace):\n",
    "        event[\"index\"] = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LOFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-03 15:32:38.792277\n",
      "max trace length: 104\n",
      "l: 1\n",
      "Number of variants: 1\n",
      "l: 2\n",
      "Number of variants: 3\n",
      "l: 3\n",
      "Number of variants: 3\n",
      "l: 4\n",
      "Number of variants: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-72-6213939bfada>:58: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  res = 1 / (sum / len(N_k))\n",
      "<ipython-input-72-6213939bfada>:74: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  res = sum / (len(N_k) * self.lrd(k, A))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l: 5\n",
      "Number of variants: 6\n",
      "l: 6\n",
      "Number of variants: 12\n",
      "l: 7\n",
      "Number of variants: 19\n",
      "l: 8\n",
      "Number of variants: 26\n",
      "l: 9\n",
      "Number of variants: 31\n",
      "l: 10\n",
      "Number of variants: 41\n",
      "l: 11\n",
      "Number of variants: 48\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-347-205ee7f6b6df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;31m# no. traces in largest variant + 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mres_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_tmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-6213939bfada>\u001b[0m in \u001b[0;36mcalculate\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-6213939bfada>\u001b[0m in \u001b[0;36mlof\u001b[1;34m(self, k, A)\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0msum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mN_k\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                 \u001b[0msum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlrd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_k\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlrd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-6213939bfada>\u001b[0m in \u001b[0;36mlrd\u001b[1;34m(self, k, A)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0msum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mN_k\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m                    \u001b[0msum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreachability_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# sum of rachability distances in k-Neighborhood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-6213939bfada>\u001b[0m in \u001b[0;36mreachability_dist\u001b[1;34m(self, k, A, B)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m## reachability distance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreachability_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mA_variant_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_to_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mB_variant_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_to_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mA_variant_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_variant_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrd_res_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# check result cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-894b62ca08cf>\u001b[0m in \u001b[0;36mtrace_to_index\u001b[1;34m(self, trace)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;31m#trace_string = trace_string + e[\"concept:name\"] + \",\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mtrace_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace_string\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"customClassifier\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\",\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mtrace_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace_string\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# remove last comma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maxiv\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pm4py\\objects\\log\\log.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(start)\n",
    "\n",
    "# find length of longest trace\n",
    "trace_len = [len(i) for i in log]\n",
    "max_trace_len = max(trace_len)\n",
    "print(\"max trace length: \" + str(max_trace_len))\n",
    "\n",
    "res = []\n",
    "\n",
    "for l in range(0, max_trace_len): # iterate from 1 to length of longest trace\n",
    "    print(\"l: \" + str(l+1))\n",
    "    # filter events by attribute \"index\". only events with index between 0 and l are kept\n",
    "    log_tmp = attributes_filter.apply_numeric_events(log, 0, l, \n",
    "                                                     parameters={constants.PARAMETER_CONSTANT_ATTRIBUTE_KEY: \"index\"})\n",
    "    \n",
    "    # run LOF calculation on filtered log\n",
    "    lof = LOF(log_tmp)\n",
    "\n",
    "    k = len(max(lof.dist.variants.values(), key=len)) + 1 # no. traces in largest variant + 1\n",
    "    res_tmp = lof.calculate(k)\n",
    "    res.append(res_tmp)\n",
    "    \n",
    "end = datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mirror results and rotate by 270 degrees\n",
    "res_rot = np.rot90(res[::-1], 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv\n",
    "np.savetxt(\"res_BPIC17_sample.csv\", res_rot, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from csv\n",
    "res_rot = np.genfromtxt(\"res_BPIC20_sample.csv\", delimiter=\",\")\n",
    "res = np.rot90(res_rot)\n",
    "res = res[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99998517, 1.81649132, ..., 5.14166176, 5.14166176,\n",
       "        5.14166176],\n",
       "       [1.        , 0.99998517, 1.78464626, ..., 1.63485424, 1.63485424,\n",
       "        1.63485424],\n",
       "       [1.        , 0.99998517, 1.8435242 , ..., 3.34324685, 3.34324685,\n",
       "        3.34324685],\n",
       "       ...,\n",
       "       [1.        , 0.99998517, 0.99211203, ..., 0.99366459, 0.99366459,\n",
       "        0.99366459],\n",
       "       [1.        , 0.99998517, 0.99211203, ..., 0.99366459, 0.99366459,\n",
       "        0.99366459],\n",
       "       [1.        , 0.99998517, 1.04075619, ..., 1.08762159, 1.08762159,\n",
       "        1.08762159]])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cutoffs for anomaly at each length\n",
    "cutoffs95 = []\n",
    "cutoffs85 = []\n",
    "cutoffs75 = []\n",
    "cutoffs50 = []\n",
    "for l in range(len(res)):\n",
    "    r = []\n",
    "    for t in range(len(res_rot)):\n",
    "        if len(log[t]) >= l + 1:\n",
    "            r.append(res[l][t])\n",
    "    cutoffs50.append(np.percentile(r, 50))\n",
    "    cutoffs85.append(np.percentile(r, 85))\n",
    "    cutoffs95.append(np.percentile(r, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify traces at each point\n",
    "classification = [None] * len(res_rot)\n",
    "\n",
    "for j, trace_res in enumerate(res_rot):\n",
    "    classification_trace = [None] * len(log[j])\n",
    "    for i, r in enumerate(trace_res):\n",
    "        if i < len(log[j]):\n",
    "            if r > cutoffs50[i]:\n",
    "                classification_trace[i] = \"anomaly\"\n",
    "            else:\n",
    "                classification_trace[i] = \"no anomaly\"\n",
    "    classification[j] = classification_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.9960172390636931,\n",
       " 1.0141779837752392,\n",
       " 1.449660175242035,\n",
       " 1.483283527196964,\n",
       " 1.5968136913981197,\n",
       " 1.743271442513729,\n",
       " 1.598951061104271,\n",
       " 1.8314951912122028,\n",
       " 2.100894225300608,\n",
       " 2.3367419705205403,\n",
       " 2.6120536165973642,\n",
       " 2.8872118451840745,\n",
       " 3.1726639320901615,\n",
       " 3.4241994237131523,\n",
       " 3.7756192754700315,\n",
       " 4.0758992434821435,\n",
       " 4.310665017564494,\n",
       " 4.682986065340565,\n",
       " 5.039655983205424,\n",
       " 5.3576448784553605,\n",
       " 5.634344693952617,\n",
       " 6.159672640524114,\n",
       " 6.491456792186284,\n",
       " 6.770600294497551,\n",
       " 7.0859214470283,\n",
       " 7.410911005504505,\n",
       " 7.553470223855971,\n",
       " 7.858152670901335,\n",
       " 8.578045471432864,\n",
       " 8.913729983303785,\n",
       " 9.22343583420026,\n",
       " 9.558610919115036,\n",
       " 9.877995045915053,\n",
       " 9.873410580392505]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoffs75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6004982448193863\n",
      "0.39950175518061376\n"
     ]
    }
   ],
   "source": [
    "na = 0\n",
    "a = 0\n",
    "for t in classification:\n",
    "    for c in t:\n",
    "        if c == \"no anomaly\":\n",
    "            na = na+1\n",
    "        elif c == \"anomaly\":\n",
    "            a = a+1\n",
    "            \n",
    "t = na + a\n",
    "print(na/t)\n",
    "print(a/t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = []\n",
    "for trace in log:\n",
    "    tlist = []\n",
    "    for i, event in enumerate(trace):\n",
    "        tlist.append(event[\"customClassifier\"])\n",
    "    lists.append(tlist)\n",
    "\n",
    "#random.seed(1633048)\n",
    "\n",
    "# split data into training and test\n",
    "lists_train, lists_test, is_anomaly_train, is_anomaly_test = ms.train_test_split(lists, classification, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.50531914893617"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(len, lists_train))/float(len(lists_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model\n",
    "- Discrete observations\n",
    "- Two states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = pom.HiddenMarkovModel.from_samples(\n",
    "    pom.DiscreteDistribution, \n",
    "    n_components=2,\n",
    "    X=lists_train, \n",
    "    labels=is_anomaly_train,\n",
    "    #state_names=[\"anomaly\", \"no anomaly\", \"unknown\"],\n",
    "    state_names=[\"no anomaly\", \"anomaly\"],\n",
    "    algorithm=\"labeled\")\n",
    "model1.bake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : {\n",
       "         \"class\" : \"Distribution\",\n",
       "         \"dtype\" : \"numpy.str_\",\n",
       "         \"name\" : \"DiscreteDistribution\",\n",
       "         \"parameters\" : [\n",
       "             {\n",
       "                 \"01_BB_540\" : 0.0010136847440446021,\n",
       "                 \"01_BB_630\" : 0.0,\n",
       "                 \"01_BB_770\" : 0.0015205271160669033,\n",
       "                 \"01_BB_775\" : 0.0010136847440446021,\n",
       "                 \"01_HOOFD_010\" : 0.00912316269640142,\n",
       "                 \"01_HOOFD_011\" : 0.006588950836289914,\n",
       "                 \"01_HOOFD_015\" : 0.021794221996958945,\n",
       "                 \"01_HOOFD_020\" : 0.015712113532691332,\n",
       "                 \"01_HOOFD_030_1\" : 0.02331474911302585,\n",
       "                 \"01_HOOFD_030_2\" : 0.02280790674100355,\n",
       "                 \"01_HOOFD_040\" : 0.013177901672579827,\n",
       "                 \"01_HOOFD_050\" : 0.00963000506842372,\n",
       "                 \"01_HOOFD_055\" : 0.00506842372022301,\n",
       "                 \"01_HOOFD_060\" : 0.008109477952356817,\n",
       "                 \"01_HOOFD_061\" : 0.012671059300557527,\n",
       "                 \"01_HOOFD_065_0\" : 0.007602635580334516,\n",
       "                 \"01_HOOFD_065_1\" : 0.015205271160669031,\n",
       "                 \"01_HOOFD_065_2\" : 0.013177901672579827,\n",
       "                 \"01_HOOFD_090\" : 0.0035478966041561076,\n",
       "                 \"01_HOOFD_099\" : 0.002534211860111505,\n",
       "                 \"01_HOOFD_100\" : 0.007095793208312215,\n",
       "                 \"01_HOOFD_100_0\" : 0.006082108464267613,\n",
       "                 \"01_HOOFD_101\" : 0.016218955904713634,\n",
       "                 \"01_HOOFD_110\" : 0.00912316269640142,\n",
       "                 \"01_HOOFD_110_0\" : 0.01013684744044602,\n",
       "                 \"01_HOOFD_110_1\" : 0.005575266092245312,\n",
       "                 \"01_HOOFD_110_2\" : 0.00506842372022301,\n",
       "                 \"01_HOOFD_120\" : 0.00963000506842372,\n",
       "                 \"01_HOOFD_130\" : 0.0040547389761784085,\n",
       "                 \"01_HOOFD_180\" : 0.019766852508869743,\n",
       "                 \"01_HOOFD_181\" : 0.0010136847440446021,\n",
       "                 \"01_HOOFD_190\" : 0.0035478966041561076,\n",
       "                 \"01_HOOFD_190_1\" : 0.0020273694880892043,\n",
       "                 \"01_HOOFD_190_2\" : 0.0030410542321338066,\n",
       "                 \"01_HOOFD_193\" : 0.0020273694880892043,\n",
       "                 \"01_HOOFD_195\" : 0.017739483020780537,\n",
       "                 \"01_HOOFD_195_1\" : 0.0,\n",
       "                 \"01_HOOFD_195_2\" : 0.0,\n",
       "                 \"01_HOOFD_196\" : 0.008616320324379118,\n",
       "                 \"01_HOOFD_200\" : 0.02027369488089204,\n",
       "                 \"01_HOOFD_205\" : 0.0015205271160669033,\n",
       "                 \"01_HOOFD_210_1\" : 0.0010136847440446021,\n",
       "                 \"01_HOOFD_210_2\" : 0.0010136847440446021,\n",
       "                 \"01_HOOFD_250\" : 0.007095793208312215,\n",
       "                 \"01_HOOFD_250_0\" : 0.002534211860111505,\n",
       "                 \"01_HOOFD_250_1\" : 0.01013684744044602,\n",
       "                 \"01_HOOFD_250_2\" : 0.00963000506842372,\n",
       "                 \"01_HOOFD_260\" : 0.007095793208312215,\n",
       "                 \"01_HOOFD_270\" : 0.0040547389761784085,\n",
       "                 \"01_HOOFD_330\" : 0.01824632539280284,\n",
       "                 \"01_HOOFD_350_1\" : 0.0,\n",
       "                 \"01_HOOFD_350_2\" : 0.0005068423720223011,\n",
       "                 \"01_HOOFD_370\" : 0.015712113532691332,\n",
       "                 \"01_HOOFD_375\" : 0.01875316776482514,\n",
       "                 \"01_HOOFD_380\" : 0.019766852508869743,\n",
       "                 \"01_HOOFD_410_0\" : 0.0,\n",
       "                 \"01_HOOFD_420\" : 0.0005068423720223011,\n",
       "                 \"01_HOOFD_430\" : 0.016218955904713634,\n",
       "                 \"01_HOOFD_440_1\" : 0.0035478966041561076,\n",
       "                 \"01_HOOFD_440_1a\" : 0.0020273694880892043,\n",
       "                 \"01_HOOFD_440_2\" : 0.0035478966041561076,\n",
       "                 \"01_HOOFD_445\" : 0.0035478966041561076,\n",
       "                 \"01_HOOFD_446\" : 0.0030410542321338066,\n",
       "                 \"01_HOOFD_450\" : 0.0015205271160669033,\n",
       "                 \"01_HOOFD_455\" : 0.0015205271160669033,\n",
       "                 \"01_HOOFD_459\" : 0.0010136847440446021,\n",
       "                 \"01_HOOFD_460\" : 0.0020273694880892043,\n",
       "                 \"01_HOOFD_460a\" : 0.0010136847440446021,\n",
       "                 \"01_HOOFD_465\" : 0.002534211860111505,\n",
       "                 \"01_HOOFD_470\" : 0.00506842372022301,\n",
       "                 \"01_HOOFD_480\" : 0.016725798276735936,\n",
       "                 \"01_HOOFD_490_1\" : 0.016218955904713634,\n",
       "                 \"01_HOOFD_490_1a\" : 0.008109477952356817,\n",
       "                 \"01_HOOFD_490_2\" : 0.015205271160669031,\n",
       "                 \"01_HOOFD_490_3\" : 0.006588950836289914,\n",
       "                 \"01_HOOFD_490_3a\" : 0.0,\n",
       "                 \"01_HOOFD_490_4\" : 0.011150532184490624,\n",
       "                 \"01_HOOFD_490_5\" : 0.005575266092245312,\n",
       "                 \"01_HOOFD_490_5a\" : 0.0035478966041561076,\n",
       "                 \"01_HOOFD_491\" : 0.00912316269640142,\n",
       "                 \"01_HOOFD_491a\" : 0.0005068423720223011,\n",
       "                 \"01_HOOFD_492_0\" : 0.0020273694880892043,\n",
       "                 \"01_HOOFD_492_1\" : 0.0,\n",
       "                 \"01_HOOFD_492_2\" : 0.0,\n",
       "                 \"01_HOOFD_493\" : 0.0020273694880892043,\n",
       "                 \"01_HOOFD_494a\" : 0.006082108464267613,\n",
       "                 \"01_HOOFD_495\" : 0.012671059300557527,\n",
       "                 \"01_HOOFD_500\" : 0.008616320324379118,\n",
       "                 \"01_HOOFD_505\" : 0.0015205271160669033,\n",
       "                 \"01_HOOFD_510_0\" : 0.005575266092245312,\n",
       "                 \"01_HOOFD_510_1\" : 0.013684744044602128,\n",
       "                 \"01_HOOFD_510_2\" : 0.008616320324379118,\n",
       "                 \"01_HOOFD_510_2a\" : 0.00456158134820071,\n",
       "                 \"01_HOOFD_510_3\" : 0.007095793208312215,\n",
       "                 \"01_HOOFD_510_4\" : 0.00456158134820071,\n",
       "                 \"01_HOOFD_515\" : 0.005575266092245312,\n",
       "                 \"01_HOOFD_516\" : 0.0,\n",
       "                 \"01_HOOFD_516a\" : 0.0,\n",
       "                 \"01_HOOFD_519\" : 0.0030410542321338066,\n",
       "                 \"01_HOOFD_520\" : 0.005575266092245312,\n",
       "                 \"01_HOOFD_530\" : 0.0005068423720223011,\n",
       "                 \"01_HOOFD_530a\" : 0.0,\n",
       "                 \"01_HOOFD_532\" : 0.0005068423720223011,\n",
       "                 \"01_HOOFD_540\" : 0.0015205271160669033,\n",
       "                 \"01_HOOFD_550\" : 0.0005068423720223011,\n",
       "                 \"01_HOOFD_570\" : 0.0005068423720223011,\n",
       "                 \"01_HOOFD_580_1\" : 0.0005068423720223011,\n",
       "                 \"01_HOOFD_580_2\" : 0.0005068423720223011,\n",
       "                 \"01_HOOFD_790\" : 0.0005068423720223011,\n",
       "                 \"01_HOOFD_800\" : 0.0,\n",
       "                 \"01_HOOFD_809\" : 0.0010136847440446021,\n",
       "                 \"01_HOOFD_809c\" : 0.0010136847440446021,\n",
       "                 \"01_HOOFD_810\" : 0.0015205271160669033,\n",
       "                 \"01_HOOFD_811\" : 0.0015205271160669033,\n",
       "                 \"01_HOOFD_814\" : 0.0010136847440446021,\n",
       "                 \"01_HOOFD_815\" : 0.0015205271160669033,\n",
       "                 \"01_HOOFD_820\" : 0.0005068423720223011,\n",
       "                 \"02_DRZ_010\" : 0.00506842372022301,\n",
       "                 \"03_GBH_005\" : 0.006588950836289914,\n",
       "                 \"03_VD_060_0\" : 0.0020273694880892043,\n",
       "                 \"04_BPT_005\" : 0.006588950836289914,\n",
       "                 \"04_BPT_009\" : 0.0010136847440446021,\n",
       "                 \"04_BPT_010\" : 0.0020273694880892043,\n",
       "                 \"04_BPT_020\" : 0.002534211860111505,\n",
       "                 \"04_BPT_021\" : 0.0015205271160669033,\n",
       "                 \"04_BPT_029\" : 0.0015205271160669033,\n",
       "                 \"04_BPT_030\" : 0.0020273694880892043,\n",
       "                 \"04_BPT_040\" : 0.0015205271160669033,\n",
       "                 \"04_BPT_041\" : 0.0005068423720223011,\n",
       "                 \"04_BPT_050\" : 0.0005068423720223011,\n",
       "                 \"04_BPT_060\" : 0.0005068423720223011,\n",
       "                 \"05_EIND_010\" : 0.01469842878864673,\n",
       "                 \"05_EIND_011\" : 0.0005068423720223011,\n",
       "                 \"05_EIND_020\" : 0.0020273694880892043,\n",
       "                 \"05_EIND_020_0\" : 0.0005068423720223011,\n",
       "                 \"05_EIND_025\" : 0.0015205271160669033,\n",
       "                 \"05_EIND_030_0\" : 0.0005068423720223011,\n",
       "                 \"05_EIND_030_1\" : 0.0020273694880892043,\n",
       "                 \"05_EIND_030_2\" : 0.0020273694880892043,\n",
       "                 \"05_EIND_040\" : 0.0005068423720223011,\n",
       "                 \"05_EIND_050\" : 0.0005068423720223011,\n",
       "                 \"05_EIND_065\" : 0.0020273694880892043,\n",
       "                 \"06_VD_010\" : 0.00912316269640142,\n",
       "                 \"06_VD_020\" : 0.00506842372022301,\n",
       "                 \"06_VD_020_1\" : 0.0,\n",
       "                 \"06_VD_020_2\" : 0.0,\n",
       "                 \"06_VD_030\" : 0.0,\n",
       "                 \"06_VD_030_1\" : 0.005575266092245312,\n",
       "                 \"06_VD_030_1a\" : 0.002534211860111505,\n",
       "                 \"06_VD_030_2\" : 0.00506842372022301,\n",
       "                 \"06_VD_030_3\" : 0.0035478966041561076,\n",
       "                 \"06_VD_030_3a\" : 0.0015205271160669033,\n",
       "                 \"06_VD_030_4\" : 0.0040547389761784085,\n",
       "                 \"06_VD_030_5\" : 0.0020273694880892043,\n",
       "                 \"06_VD_030_5a\" : 0.0010136847440446021,\n",
       "                 \"06_VD_035\" : 0.0040547389761784085,\n",
       "                 \"06_VD_040\" : 0.0,\n",
       "                 \"06_VD_050\" : 0.0,\n",
       "                 \"06_VD_060\" : 0.0015205271160669033,\n",
       "                 \"06_VD_060_1\" : 0.0020273694880892043,\n",
       "                 \"06_VD_060_2\" : 0.0035478966041561076,\n",
       "                 \"06_VD_060_2a\" : 0.002534211860111505,\n",
       "                 \"06_VD_060_3\" : 0.0040547389761784085,\n",
       "                 \"06_VD_060_4\" : 0.0010136847440446021,\n",
       "                 \"06_VD_070\" : 0.0015205271160669033,\n",
       "                 \"06_VD_100\" : 0.0,\n",
       "                 \"06_VD_140\" : 0.0,\n",
       "                 \"07_OPS_010\" : 0.0035478966041561076,\n",
       "                 \"07_OPS_070\" : 0.0005068423720223011,\n",
       "                 \"07_OPS_080_1\" : 0.0005068423720223011,\n",
       "                 \"07_OPS_080_2\" : 0.0005068423720223011,\n",
       "                 \"08_AWB45_005\" : 0.01824632539280284,\n",
       "                 \"08_AWB45_010\" : 0.007095793208312215,\n",
       "                 \"08_AWB45_020_0\" : 0.002534211860111505,\n",
       "                 \"08_AWB45_020_1\" : 0.006082108464267613,\n",
       "                 \"08_AWB45_020_2\" : 0.008109477952356817,\n",
       "                 \"08_AWB45_025\" : 0.00506842372022301,\n",
       "                 \"08_AWB45_030\" : 0.006588950836289914,\n",
       "                 \"08_AWB45_040\" : 0.006588950836289914,\n",
       "                 \"08_AWB45_045\" : 0.0040547389761784085,\n",
       "                 \"08_AWB45_051_0\" : 0.0040547389761784085,\n",
       "                 \"08_AWB45_051_1\" : 0.0005068423720223011,\n",
       "                 \"08_AWB45_051_2\" : 0.0005068423720223011,\n",
       "                 \"08_AWB45_060\" : 0.0,\n",
       "                 \"08_AWB45_070_1\" : 0.0,\n",
       "                 \"08_AWB45_070_2\" : 0.0005068423720223011,\n",
       "                 \"08_AWB45_070_3\" : 0.0005068423720223011,\n",
       "                 \"08_AWB45_090_1\" : 0.0,\n",
       "                 \"08_AWB45_090_2\" : 0.0,\n",
       "                 \"08_AWB45_170\" : 0.0015205271160669033,\n",
       "                 \"09_AH_I_010\" : 0.01824632539280284,\n",
       "                 \"09_AWB45_005\" : 0.0020273694880892043,\n",
       "                 \"10_UOV_010\" : 0.0030410542321338066,\n",
       "                 \"10_UOV_030\" : 0.0020273694880892043,\n",
       "                 \"10_UOV_030a\" : 0.0005068423720223011,\n",
       "                 \"10_UOV_035\" : 0.0015205271160669033,\n",
       "                 \"10_UOV_039\" : 0.0010136847440446021,\n",
       "                 \"10_UOV_040\" : 0.0015205271160669033,\n",
       "                 \"10_UOV_045\" : 0.0015205271160669033,\n",
       "                 \"10_UOV_050_0\" : 0.0010136847440446021,\n",
       "                 \"10_UOV_050_1\" : 0.0020273694880892043,\n",
       "                 \"10_UOV_050_2\" : 0.0020273694880892043,\n",
       "                 \"10_UOV_050_2a\" : 0.0005068423720223011,\n",
       "                 \"10_UOV_050_3\" : 0.0005068423720223011,\n",
       "                 \"10_UOV_050_4\" : 0.0005068423720223011,\n",
       "                 \"10_UOV_060\" : 0.0020273694880892043,\n",
       "                 \"10_UOV_061\" : 0.0005068423720223011,\n",
       "                 \"10_UOV_065\" : 0.0010136847440446021,\n",
       "                 \"10_UOV_066\" : 0.0005068423720223011,\n",
       "                 \"10_UOV_070\" : 0.0010136847440446021,\n",
       "                 \"10_UOV_080\" : 0.0010136847440446021,\n",
       "                 \"10_UOV_100\" : 0.0010136847440446021,\n",
       "                 \"10_UOV_120\" : 0.0010136847440446021,\n",
       "                 \"10_UOV_140\" : 0.0005068423720223011,\n",
       "                 \"10_UOV_150\" : 0.0,\n",
       "                 \"10_UOV_160\" : 0.0005068423720223011,\n",
       "                 \"10_UOV_170\" : 0.0,\n",
       "                 \"10_UOV_180\" : 0.0015205271160669033,\n",
       "                 \"11_AH_II_010\" : 0.015205271160669031,\n",
       "                 \"11_AH_II_020\" : 0.0,\n",
       "                 \"11_AH_II_020_1\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_020_2\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_030\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_035\" : 0.0010136847440446021,\n",
       "                 \"11_AH_II_036\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_037_1\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_037_2\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_040\" : 0.0010136847440446021,\n",
       "                 \"11_AH_II_040_d\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_040a\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_040b\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_040c\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_055\" : 0.0,\n",
       "                 \"11_AH_II_070\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_070_1\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_070_2\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_070_3\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_070_3a\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_100\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_130\" : 0.0010136847440446021,\n",
       "                 \"11_AH_II_140\" : 0.0005068423720223011,\n",
       "                 \"11_AH_II_145\" : 0.0005068423720223011,\n",
       "                 \"12_AP_010\" : 0.0,\n",
       "                 \"12_AP_UOV_010\" : 0.0005068423720223011,\n",
       "                 \"13_CRD_010\" : 0.01013684744044602,\n",
       "                 \"14_VRIJ_010\" : 0.007602635580334516,\n",
       "                 \"15_NGV_010\" : 0.0020273694880892043\n",
       "             }\n",
       "         ],\n",
       "         \"frozen\" : false\n",
       "     },\n",
       "     \"name\" : \"anomaly\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : {\n",
       "         \"class\" : \"Distribution\",\n",
       "         \"dtype\" : \"numpy.str_\",\n",
       "         \"name\" : \"DiscreteDistribution\",\n",
       "         \"parameters\" : [\n",
       "             {\n",
       "                 \"01_BB_540\" : 0.005057471264367816,\n",
       "                 \"01_BB_630\" : 0.0004597701149425287,\n",
       "                 \"01_BB_770\" : 0.004137931034482759,\n",
       "                 \"01_BB_775\" : 0.004137931034482759,\n",
       "                 \"01_HOOFD_010\" : 0.035402298850574714,\n",
       "                 \"01_HOOFD_011\" : 0.02436781609195402,\n",
       "                 \"01_HOOFD_015\" : 0.023908045977011495,\n",
       "                 \"01_HOOFD_020\" : 0.029425287356321838,\n",
       "                 \"01_HOOFD_030_1\" : 0.020229885057471263,\n",
       "                 \"01_HOOFD_030_2\" : 0.015172413793103448,\n",
       "                 \"01_HOOFD_040\" : 0.0009195402298850574,\n",
       "                 \"01_HOOFD_050\" : 0.006436781609195402,\n",
       "                 \"01_HOOFD_055\" : 0.0022988505747126436,\n",
       "                 \"01_HOOFD_060\" : 0.005057471264367816,\n",
       "                 \"01_HOOFD_061\" : 0.013793103448275862,\n",
       "                 \"01_HOOFD_065_0\" : 0.013793103448275862,\n",
       "                 \"01_HOOFD_065_1\" : 0.008735632183908045,\n",
       "                 \"01_HOOFD_065_2\" : 0.011034482758620689,\n",
       "                 \"01_HOOFD_090\" : 0.004137931034482759,\n",
       "                 \"01_HOOFD_099\" : 0.0022988505747126436,\n",
       "                 \"01_HOOFD_100\" : 0.005057471264367816,\n",
       "                 \"01_HOOFD_100_0\" : 0.010114942528735632,\n",
       "                 \"01_HOOFD_101\" : 0.01747126436781609,\n",
       "                 \"01_HOOFD_110\" : 0.010574712643678161,\n",
       "                 \"01_HOOFD_110_0\" : 0.009195402298850575,\n",
       "                 \"01_HOOFD_110_1\" : 0.0018390804597701149,\n",
       "                 \"01_HOOFD_110_2\" : 0.0022988505747126436,\n",
       "                 \"01_HOOFD_120\" : 0.010114942528735632,\n",
       "                 \"01_HOOFD_130\" : 0.005057471264367816,\n",
       "                 \"01_HOOFD_180\" : 0.02436781609195402,\n",
       "                 \"01_HOOFD_181\" : 0.0004597701149425287,\n",
       "                 \"01_HOOFD_190\" : 0.006436781609195402,\n",
       "                 \"01_HOOFD_190_1\" : 0.0022988505747126436,\n",
       "                 \"01_HOOFD_190_2\" : 0.001379310344827586,\n",
       "                 \"01_HOOFD_193\" : 0.003218390804597701,\n",
       "                 \"01_HOOFD_195\" : 0.016091954022988506,\n",
       "                 \"01_HOOFD_195_1\" : 0.0004597701149425287,\n",
       "                 \"01_HOOFD_195_2\" : 0.0004597701149425287,\n",
       "                 \"01_HOOFD_196\" : 0.006896551724137931,\n",
       "                 \"01_HOOFD_200\" : 0.01885057471264368,\n",
       "                 \"01_HOOFD_205\" : 0.003218390804597701,\n",
       "                 \"01_HOOFD_210_1\" : 0.0004597701149425287,\n",
       "                 \"01_HOOFD_210_2\" : 0.0004597701149425287,\n",
       "                 \"01_HOOFD_250\" : 0.006896551724137931,\n",
       "                 \"01_HOOFD_250_0\" : 0.001379310344827586,\n",
       "                 \"01_HOOFD_250_1\" : 0.009655172413793104,\n",
       "                 \"01_HOOFD_250_2\" : 0.010114942528735632,\n",
       "                 \"01_HOOFD_260\" : 0.006436781609195402,\n",
       "                 \"01_HOOFD_270\" : 0.002758620689655172,\n",
       "                 \"01_HOOFD_330\" : 0.016091954022988506,\n",
       "                 \"01_HOOFD_350_1\" : 0.0009195402298850574,\n",
       "                 \"01_HOOFD_350_2\" : 0.0004597701149425287,\n",
       "                 \"01_HOOFD_370\" : 0.016551724137931035,\n",
       "                 \"01_HOOFD_375\" : 0.017011494252873564,\n",
       "                 \"01_HOOFD_380\" : 0.016551724137931035,\n",
       "                 \"01_HOOFD_410_0\" : 0.0004597701149425287,\n",
       "                 \"01_HOOFD_420\" : 0.0,\n",
       "                 \"01_HOOFD_430\" : 0.016551724137931035,\n",
       "                 \"01_HOOFD_440_1\" : 0.0,\n",
       "                 \"01_HOOFD_440_1a\" : 0.0,\n",
       "                 \"01_HOOFD_440_2\" : 0.0,\n",
       "                 \"01_HOOFD_445\" : 0.0,\n",
       "                 \"01_HOOFD_446\" : 0.0004597701149425287,\n",
       "                 \"01_HOOFD_450\" : 0.0,\n",
       "                 \"01_HOOFD_455\" : 0.0,\n",
       "                 \"01_HOOFD_459\" : 0.0004597701149425287,\n",
       "                 \"01_HOOFD_460\" : 0.0009195402298850574,\n",
       "                 \"01_HOOFD_460a\" : 0.0004597701149425287,\n",
       "                 \"01_HOOFD_465\" : 0.0004597701149425287,\n",
       "                 \"01_HOOFD_470\" : 0.004137931034482759,\n",
       "                 \"01_HOOFD_480\" : 0.016091954022988506,\n",
       "                 \"01_HOOFD_490_1\" : 0.01839080459770115,\n",
       "                 \"01_HOOFD_490_1a\" : 0.008735632183908045,\n",
       "                 \"01_HOOFD_490_2\" : 0.01793103448275862,\n",
       "                 \"01_HOOFD_490_3\" : 0.006896551724137931,\n",
       "                 \"01_HOOFD_490_3a\" : 0.0009195402298850574,\n",
       "                 \"01_HOOFD_490_4\" : 0.011954022988505748,\n",
       "                 \"01_HOOFD_490_5\" : 0.011494252873563218,\n",
       "                 \"01_HOOFD_490_5a\" : 0.010114942528735632,\n",
       "                 \"01_HOOFD_491\" : 0.011954022988505748,\n",
       "                 \"01_HOOFD_491a\" : 0.0018390804597701149,\n",
       "                 \"01_HOOFD_492_0\" : 0.0009195402298850574,\n",
       "                 \"01_HOOFD_492_1\" : 0.0004597701149425287,\n",
       "                 \"01_HOOFD_492_2\" : 0.0004597701149425287,\n",
       "                 \"01_HOOFD_493\" : 0.0009195402298850574,\n",
       "                 \"01_HOOFD_494a\" : 0.009655172413793104,\n",
       "                 \"01_HOOFD_495\" : 0.016551724137931035,\n",
       "                 \"01_HOOFD_500\" : 0.014252873563218391,\n",
       "                 \"01_HOOFD_505\" : 0.0018390804597701149,\n",
       "                 \"01_HOOFD_510_0\" : 0.010574712643678161,\n",
       "                 \"01_HOOFD_510_1\" : 0.019310344827586208,\n",
       "                 \"01_HOOFD_510_2\" : 0.01839080459770115,\n",
       "                 \"01_HOOFD_510_2a\" : 0.010574712643678161,\n",
       "                 \"01_HOOFD_510_3\" : 0.013333333333333334,\n",
       "                 \"01_HOOFD_510_4\" : 0.014252873563218391,\n",
       "                 \"01_HOOFD_515\" : 0.014712643678160919,\n",
       "                 \"01_HOOFD_516\" : 0.0018390804597701149,\n",
       "                 \"01_HOOFD_516a\" : 0.0009195402298850574,\n",
       "                 \"01_HOOFD_519\" : 0.005517241379310344,\n",
       "                 \"01_HOOFD_520\" : 0.006436781609195402,\n",
       "                 \"01_HOOFD_530\" : 0.002758620689655172,\n",
       "                 \"01_HOOFD_530a\" : 0.0,\n",
       "                 \"01_HOOFD_532\" : 0.001379310344827586,\n",
       "                 \"01_HOOFD_540\" : 0.001379310344827586,\n",
       "                 \"01_HOOFD_550\" : 0.0,\n",
       "                 \"01_HOOFD_570\" : 0.0,\n",
       "                 \"01_HOOFD_580_1\" : 0.0,\n",
       "                 \"01_HOOFD_580_2\" : 0.0,\n",
       "                 \"01_HOOFD_790\" : 0.0,\n",
       "                 \"01_HOOFD_800\" : 0.0,\n",
       "                 \"01_HOOFD_809\" : 0.0036781609195402297,\n",
       "                 \"01_HOOFD_809c\" : 0.001379310344827586,\n",
       "                 \"01_HOOFD_810\" : 0.004137931034482759,\n",
       "                 \"01_HOOFD_811\" : 0.003218390804597701,\n",
       "                 \"01_HOOFD_814\" : 0.004137931034482759,\n",
       "                 \"01_HOOFD_815\" : 0.003218390804597701,\n",
       "                 \"01_HOOFD_820\" : 0.0009195402298850574,\n",
       "                 \"02_DRZ_010\" : 0.02574712643678161,\n",
       "                 \"03_GBH_005\" : 0.001379310344827586,\n",
       "                 \"03_VD_060_0\" : 0.0004597701149425287,\n",
       "                 \"04_BPT_005\" : 0.02482758620689655,\n",
       "                 \"04_BPT_009\" : 0.0,\n",
       "                 \"04_BPT_010\" : 0.0009195402298850574,\n",
       "                 \"04_BPT_020\" : 0.001379310344827586,\n",
       "                 \"04_BPT_021\" : 0.0,\n",
       "                 \"04_BPT_029\" : 0.0,\n",
       "                 \"04_BPT_030\" : 0.001379310344827586,\n",
       "                 \"04_BPT_040\" : 0.0,\n",
       "                 \"04_BPT_041\" : 0.0,\n",
       "                 \"04_BPT_050\" : 0.0,\n",
       "                 \"04_BPT_060\" : 0.0,\n",
       "                 \"05_EIND_010\" : 0.003218390804597701,\n",
       "                 \"05_EIND_011\" : 0.0,\n",
       "                 \"05_EIND_020\" : 0.0004597701149425287,\n",
       "                 \"05_EIND_020_0\" : 0.0,\n",
       "                 \"05_EIND_025\" : 0.0004597701149425287,\n",
       "                 \"05_EIND_030_0\" : 0.0,\n",
       "                 \"05_EIND_030_1\" : 0.0,\n",
       "                 \"05_EIND_030_2\" : 0.0,\n",
       "                 \"05_EIND_040\" : 0.0,\n",
       "                 \"05_EIND_050\" : 0.0,\n",
       "                 \"05_EIND_065\" : 0.0,\n",
       "                 \"06_VD_010\" : 0.005517241379310344,\n",
       "                 \"06_VD_020\" : 0.0009195402298850574,\n",
       "                 \"06_VD_020_1\" : 0.0009195402298850574,\n",
       "                 \"06_VD_020_2\" : 0.0009195402298850574,\n",
       "                 \"06_VD_030\" : 0.0009195402298850574,\n",
       "                 \"06_VD_030_1\" : 0.0004597701149425287,\n",
       "                 \"06_VD_030_1a\" : 0.0,\n",
       "                 \"06_VD_030_2\" : 0.0009195402298850574,\n",
       "                 \"06_VD_030_3\" : 0.0004597701149425287,\n",
       "                 \"06_VD_030_3a\" : 0.0,\n",
       "                 \"06_VD_030_4\" : 0.0,\n",
       "                 \"06_VD_030_5\" : 0.0,\n",
       "                 \"06_VD_030_5a\" : 0.0,\n",
       "                 \"06_VD_035\" : 0.0,\n",
       "                 \"06_VD_040\" : 0.0009195402298850574,\n",
       "                 \"06_VD_050\" : 0.0009195402298850574,\n",
       "                 \"06_VD_060\" : 0.0009195402298850574,\n",
       "                 \"06_VD_060_1\" : 0.0,\n",
       "                 \"06_VD_060_2\" : 0.0,\n",
       "                 \"06_VD_060_2a\" : 0.0,\n",
       "                 \"06_VD_060_3\" : 0.0,\n",
       "                 \"06_VD_060_4\" : 0.0,\n",
       "                 \"06_VD_070\" : 0.001379310344827586,\n",
       "                 \"06_VD_100\" : 0.0004597701149425287,\n",
       "                 \"06_VD_140\" : 0.0004597701149425287,\n",
       "                 \"07_OPS_010\" : 0.0018390804597701149,\n",
       "                 \"07_OPS_070\" : 0.0,\n",
       "                 \"07_OPS_080_1\" : 0.0,\n",
       "                 \"07_OPS_080_2\" : 0.0,\n",
       "                 \"08_AWB45_005\" : 0.013333333333333334,\n",
       "                 \"08_AWB45_010\" : 0.006436781609195402,\n",
       "                 \"08_AWB45_020_0\" : 0.004137931034482759,\n",
       "                 \"08_AWB45_020_1\" : 0.006896551724137931,\n",
       "                 \"08_AWB45_020_2\" : 0.005057471264367816,\n",
       "                 \"08_AWB45_025\" : 0.002758620689655172,\n",
       "                 \"08_AWB45_030\" : 0.005977011494252874,\n",
       "                 \"08_AWB45_040\" : 0.005977011494252874,\n",
       "                 \"08_AWB45_045\" : 0.003218390804597701,\n",
       "                 \"08_AWB45_051_0\" : 0.003218390804597701,\n",
       "                 \"08_AWB45_051_1\" : 0.0,\n",
       "                 \"08_AWB45_051_2\" : 0.0,\n",
       "                 \"08_AWB45_060\" : 0.0004597701149425287,\n",
       "                 \"08_AWB45_070_1\" : 0.0004597701149425287,\n",
       "                 \"08_AWB45_070_2\" : 0.0,\n",
       "                 \"08_AWB45_070_3\" : 0.0,\n",
       "                 \"08_AWB45_090_1\" : 0.0,\n",
       "                 \"08_AWB45_090_2\" : 0.0004597701149425287,\n",
       "                 \"08_AWB45_170\" : 0.002758620689655172,\n",
       "                 \"09_AH_I_010\" : 0.01793103448275862,\n",
       "                 \"09_AWB45_005\" : 0.0018390804597701149,\n",
       "                 \"10_UOV_010\" : 0.0,\n",
       "                 \"10_UOV_030\" : 0.0,\n",
       "                 \"10_UOV_030a\" : 0.0004597701149425287,\n",
       "                 \"10_UOV_035\" : 0.0,\n",
       "                 \"10_UOV_039\" : 0.0,\n",
       "                 \"10_UOV_040\" : 0.0,\n",
       "                 \"10_UOV_045\" : 0.0,\n",
       "                 \"10_UOV_050_0\" : 0.0,\n",
       "                 \"10_UOV_050_1\" : 0.0,\n",
       "                 \"10_UOV_050_2\" : 0.0,\n",
       "                 \"10_UOV_050_2a\" : 0.0,\n",
       "                 \"10_UOV_050_3\" : 0.0,\n",
       "                 \"10_UOV_050_4\" : 0.0,\n",
       "                 \"10_UOV_060\" : 0.0,\n",
       "                 \"10_UOV_061\" : 0.0,\n",
       "                 \"10_UOV_065\" : 0.0,\n",
       "                 \"10_UOV_066\" : 0.0,\n",
       "                 \"10_UOV_070\" : 0.0,\n",
       "                 \"10_UOV_080\" : 0.0,\n",
       "                 \"10_UOV_100\" : 0.0,\n",
       "                 \"10_UOV_120\" : 0.0,\n",
       "                 \"10_UOV_140\" : 0.0,\n",
       "                 \"10_UOV_150\" : 0.0004597701149425287,\n",
       "                 \"10_UOV_160\" : 0.0,\n",
       "                 \"10_UOV_170\" : 0.0004597701149425287,\n",
       "                 \"10_UOV_180\" : 0.0,\n",
       "                 \"11_AH_II_010\" : 0.011034482758620689,\n",
       "                 \"11_AH_II_020\" : 0.0004597701149425287,\n",
       "                 \"11_AH_II_020_1\" : 0.0,\n",
       "                 \"11_AH_II_020_2\" : 0.0,\n",
       "                 \"11_AH_II_030\" : 0.0,\n",
       "                 \"11_AH_II_035\" : 0.0,\n",
       "                 \"11_AH_II_036\" : 0.0,\n",
       "                 \"11_AH_II_037_1\" : 0.0,\n",
       "                 \"11_AH_II_037_2\" : 0.0,\n",
       "                 \"11_AH_II_040\" : 0.0,\n",
       "                 \"11_AH_II_040_d\" : 0.0,\n",
       "                 \"11_AH_II_040a\" : 0.0,\n",
       "                 \"11_AH_II_040b\" : 0.0,\n",
       "                 \"11_AH_II_040c\" : 0.0,\n",
       "                 \"11_AH_II_055\" : 0.0004597701149425287,\n",
       "                 \"11_AH_II_070\" : 0.0,\n",
       "                 \"11_AH_II_070_1\" : 0.0,\n",
       "                 \"11_AH_II_070_2\" : 0.0,\n",
       "                 \"11_AH_II_070_3\" : 0.0,\n",
       "                 \"11_AH_II_070_3a\" : 0.0,\n",
       "                 \"11_AH_II_100\" : 0.0,\n",
       "                 \"11_AH_II_130\" : 0.0,\n",
       "                 \"11_AH_II_140\" : 0.0,\n",
       "                 \"11_AH_II_145\" : 0.0,\n",
       "                 \"12_AP_010\" : 0.0004597701149425287,\n",
       "                 \"12_AP_UOV_010\" : 0.0,\n",
       "                 \"13_CRD_010\" : 0.005977011494252874,\n",
       "                 \"14_VRIJ_010\" : 0.0,\n",
       "                 \"15_NGV_010\" : 0.001379310344827586\n",
       "             }\n",
       "         ],\n",
       "         \"frozen\" : false\n",
       "     },\n",
       "     \"name\" : \"no anomaly\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : null,\n",
       "     \"name\" : \"None-start\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : null,\n",
       "     \"name\" : \"None-end\",\n",
       "     \"weight\" : 1.0\n",
       " }]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74709884, 0.25290116, 0.        , 0.        ],\n",
       "       [0.22681704, 0.77318296, 0.        , 0.        ],\n",
       "       [0.5       , 0.5       , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.dense_transition_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR\t\t\t100.0%\n",
      "FNR\t\t\t0.0%\n",
      "\n",
      "\n",
      "TNR (specificity)\t0.0%\n",
      "TPR (sensitivity)\t100.0%\n"
     ]
    }
   ],
   "source": [
    "false_positive = 0 # anomaly incorrectly detected\n",
    "false_negative = 0 # anomaly incrrectly not detected\n",
    "true_positive = 0 # anomaly correctly detectd\n",
    "true_negative = 0 # anomaly correclty not detected\n",
    "\n",
    "for i, t in enumerate(lists_test):\n",
    "    prediction = model1.predict(t)\n",
    "    if prediction[-1] == 0 and is_anomaly_test[i][-1] == \"no anomaly\":\n",
    "        true_negative = true_negative + 1\n",
    "    if prediction[-1] == 0 and is_anomaly_test[i][-1] == \"anomaly\":\n",
    "        false_negative = false_negative + 1\n",
    "    if prediction[-1] == 1 and is_anomaly_test[i][-1] == \"no anomaly\":\n",
    "        false_positive = false_positive + 1\n",
    "    if prediction[-1] == 1 and is_anomaly_test[i][-1] == \"anomaly\":\n",
    "        true_positive = true_positive + 1\n",
    "\n",
    "TPR = true_positive / (true_positive + false_negative)\n",
    "TNR = true_negative / (true_negative + false_positive)\n",
    "        \n",
    "FPR = false_positive / (false_positive + true_negative)\n",
    "FNR = false_negative / (false_negative + true_positive)\n",
    "\n",
    "print(\"FPR\\t\\t\\t\" + str(round(FPR * 100, 1)) + \"%\")\n",
    "print(\"FNR\\t\\t\\t\" + str(round(FNR * 100, 1)) + \"%\")\n",
    "print(\"\\n\")\n",
    "print(\"TNR (specificity)\\t\" + str(round(TNR * 100, 1)) + \"%\")\n",
    "print(\"TPR (sensitivity)\\t\" + str(round(TPR * 100, 1)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1]\n",
      "['no anomaly', 'no anomaly', 'anomaly', 'anomaly', 'no anomaly']\n"
     ]
    }
   ],
   "source": [
    "print(model1.predict(lists_test[0]))\n",
    "print(is_anomaly_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg: 281\n",
      "pos: 17\n"
     ]
    }
   ],
   "source": [
    "print(\"neg: \" + str(false_positive + true_negative))\n",
    "print(\"pos: \" + str(false_negative + true_positive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR (sensitivity)\t69.9\n",
      "TNR (specificity)\t61.2\n",
      "Error Rate\t\t34.9\n"
     ]
    }
   ],
   "source": [
    "## rates over all events\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for i, t in enumerate(lists_test):\n",
    "\n",
    "    prediction = model1.predict(t)\n",
    "    for j, p in enumerate(prediction):\n",
    "        p_name = model.states[p].name\n",
    "        if p_name == \"no anomaly\" and is_anomaly_test[i][j] == \"no anomaly\":\n",
    "            tn = tn + 1\n",
    "        elif p_name == \"anomaly\" and is_anomaly_test[i][j] == \"anomaly\":\n",
    "            tp = tp + 1\n",
    "        elif p_name == \"no anomaly\" and is_anomaly_test[i][j] == \"anomaly\":\n",
    "            fn = fn + 1\n",
    "        elif p_name == \"anomaly\" and is_anomaly_test[i][j] == \"no anomaly\":\n",
    "            fp = fp + 1\n",
    "\n",
    "print(\"TPR (sensitivity)\\t\" + str(round(tp / (tp+fn) * 100, 1)))\n",
    "print(\"TNR (specificity)\\t\" + str(round(tn / (tn + fp) * 100, 1)))\n",
    "print(\"Error Rate\\t\\t\" + str(round((fp + fn)/(tp+tn+fp+fn) * 100, 1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR (sensitivity)\t63.9\n",
      "TNR (specificity)\t75.8\n",
      "Error Rate\t\t26.3\n"
     ]
    }
   ],
   "source": [
    "# rates weighted over traces\n",
    "tp_list = []\n",
    "tn_list = []\n",
    "err_list = []\n",
    "\n",
    "for i, t in enumerate(lists_test):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    err = 0\n",
    "    \n",
    "    prediction = model1.predict(t)\n",
    "    for j, p in enumerate(prediction):\n",
    "        if p == 1 and is_anomaly_test[i][j] == \"no anomaly\":\n",
    "            tn = tn + 1\n",
    "        elif p == 0 and is_anomaly_test[i][j] == \"anomaly\":\n",
    "            tp = tp + 1\n",
    "        elif p == 1 and is_anomaly_test[i][j] == \"anomaly\":\n",
    "            fn = fn + 1\n",
    "        elif p == 0 and is_anomaly_test[i][j] == \"no anomaly\":\n",
    "            fp = fp + 1\n",
    "            \n",
    "        if (tp+fn) != 0: tp_list.append(tp / (tp + fn))\n",
    "        if (tn+fp) != 0: tn_list.append(tn / (tn + fp))\n",
    "        err_list.append((fp + fn) / (tp+tn+fp+fn))\n",
    "\n",
    "\n",
    "print(\"TPR (sensitivity)\\t\" + str(round(sum(tp_list) / len(tp_list) * 100, 1)))\n",
    "print(\"TNR (specificity)\\t\" + str(round(sum(tn_list) / len(tn_list) * 100, 1)))\n",
    "print(\"Error Rate\\t\\t\" + str(round(sum(err_list) / len(err_list) * 100, 1)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
