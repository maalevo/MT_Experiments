{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import all necessary libraries ##\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "#########################\n",
    "\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.filtering.log.attributes import attributes_filter\n",
    "from pm4py.algo.filtering.log.variants import variants_filter\n",
    "from pm4py.statistics.traces.log import case_statistics\n",
    "from pm4py.objects.log.util import insert_classifier\n",
    "from pm4py.util import constants\n",
    "\n",
    "#########################\n",
    "\n",
    "import distance\n",
    "\n",
    "from similarity.levenshtein import Levenshtein\n",
    "levenshtein = Levenshtein()\n",
    "\n",
    "from similarity.damerau import Damerau\n",
    "damerau = Damerau()\n",
    "\n",
    "from pyjarowinkler import distance as jwdistance\n",
    "from similarity.jarowinkler import JaroWinkler\n",
    "jarowinkler = JaroWinkler()\n",
    "\n",
    "from similarity.weighted_levenshtein import WeightedLevenshtein\n",
    "from similarity.weighted_levenshtein import CharacterSubstitutionInterface\n",
    "import math\n",
    "from random import sample\n",
    "from random import seed\n",
    "class CharacterSubstitution(CharacterSubstitutionInterface):\n",
    "    def cost(self, c0, c1):\n",
    "        return math.inf # assign inifte weight to all substitutions\n",
    "levenshtein2 = WeightedLevenshtein(CharacterSubstitution())\n",
    "\n",
    "#########################\n",
    "\n",
    "import pomegranate as pom\n",
    "from sklearn import model_selection as ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distance:\n",
    "    \n",
    "    ### SETUP ###\n",
    "    \n",
    "    ## load dataset, generate mapping and generate strings\n",
    "    def __init__(self, log):\n",
    "        self.log = log\n",
    "        \n",
    "        self.strings = []\n",
    "        self.matrix = []\n",
    "        self.transl = {}\n",
    "        self.variant_to_Vindex = {}\n",
    "        self.index_to_variant = [] \n",
    "        #seed(1633048)\n",
    "        #self.log = sample(self.log, int(len(self.log)/10))\n",
    "        self.clear_caches()\n",
    "        \n",
    "        self.gen_trace_to_Tindex()\n",
    "        \n",
    "        self.gen_mapping()\n",
    "        self.gen_variant_strings()        \n",
    "    \n",
    "    def clear_caches(self):\n",
    "        self.Nk_res_dict = {} # N_k result cache\n",
    "    \n",
    "    ## generate mapping from activity to char\n",
    "    def gen_mapping(self):\n",
    "        ## generate mapping from activities to chars ##\n",
    "        # TODO read Activity Classifier for correct naming of activities\n",
    "        #activities = list(attributes_filter.get_attribute_values(self.log, \"concept:name\").keys())\n",
    "        activities = list(attributes_filter.get_attribute_values(self.log, \"customClassifier\").keys())\n",
    "        #activities2 = list(attributes_filter.get_attribute_values(self.log, \"lifecycle:transition\").keys())\n",
    "        #activities = [i + \"-\" + j for i, j in zip(activities2, activities2)]\n",
    "        for i, a in enumerate(activities):\n",
    "            self.transl[a] = chr(i+1)\n",
    "\n",
    "    def gen_trace_to_Tindex(self):\n",
    "        self.trace_to_Tindex = {}\n",
    "        for i, t in enumerate(self.log):\n",
    "            self.trace_to_Tindex[t] = i\n",
    "            \n",
    "            \n",
    "    ## generate strings for all variants\n",
    "    def gen_variant_strings(self):\n",
    "        self.variants = variants_filter.get_variants(self.log, parameters={variants_filter.Parameters.ACTIVITY_KEY: \"customClassifier\"}) # all variants as dictionary\n",
    "        variant_strings = list(self.variants.keys()) # variants as strings\n",
    "        self.variant_to_index = {} # dictionary to translate variant to index in list for later lookup of traces\n",
    "        \n",
    "        for i, v in enumerate(variant_strings):\n",
    "            string = \"\"\n",
    "            for e in v.split(\",\"):\n",
    "                string = string + self.transl[e] \n",
    "            \n",
    "            #self.strings.append(list_to_string(v.split(\",\")))\n",
    "            self.strings.append(string)\n",
    "            \n",
    "            self.variant_to_index[v] = i\n",
    "            self.index_to_variant.append(v)\n",
    "            \n",
    "        print(\"Number of variants: \" + str(len(self.strings)))\n",
    "    \n",
    "    ### CALCULATION ###\n",
    "    \n",
    "    ## calculate distance matrix\n",
    "    def calculate(self):\n",
    "        n = len(self.strings)\n",
    "        self.matrix = np.full((n, n), 0, dtype = np.uint8)\n",
    "\n",
    "        for i, x in enumerate(self.strings):\n",
    "            for j, y in enumerate(self.strings):\n",
    "                if j >= i: # only calculate upper right triangle of matrix\n",
    "                    #dist = distance.hamming(x, y)\n",
    "                    dist = levenshtein.distance(x, y)\n",
    "                    #dist = levenshtein2.distance(x, y)\n",
    "                    #dist = damerau.distance(x, y)\n",
    "                    #dist = (1- jarowinkler.similarity(x, y))*255\n",
    "                    #print(dist)\n",
    "                    self.matrix[i][j] = dist\n",
    "\n",
    "        # mirror upper right triangle of matrix by adding the transposition\n",
    "        self.matrix = self.matrix + self.matrix.T\n",
    "\n",
    "        return self.matrix\n",
    "    \n",
    "    ### RETRIEVAL ###\n",
    "    \n",
    "    ## translate trace to its corresponding matrix index\n",
    "    def trace_to_index(self, trace):\n",
    "        # convert trace to string tion of variant (concept:name separated by commas)\n",
    "        trace_string = \"\"\n",
    "        for e in trace:\n",
    "            #trace_string = trace_string + e[\"concept:name\"] + \",\"\n",
    "            trace_string = trace_string + e[\"customClassifier\"] + \",\"\n",
    "        trace_string = trace_string[:-1] # remove last comma\n",
    "\n",
    "        return self.variant_to_index[trace_string]\n",
    "    \n",
    "    ## translate matrix (variant) index to trace indices\n",
    "    def index_to_traces(self, i):\n",
    "        variant_string = self.index_to_variant[i]\n",
    "        traces = self.variants[variant_string] # retrieve traces from variant dictionary\n",
    "        filtered_variants = {variant_string: traces} # generate new variants dictionary with only one variant\n",
    "        \n",
    "        filtered_log = variants_filter.apply(self.log, filtered_variants, parameters={variants_filter.Parameters.ACTIVITY_KEY: \"customClassifier\"})\n",
    "        traces = []\n",
    "        for t in filtered_log:\n",
    "            traces.append(t)\n",
    "        \n",
    "        return traces\n",
    "        \n",
    "    \n",
    "    ## retrieve distance of two traces from matrix\n",
    "    def dist(self, t1, t2):\n",
    "        i1 = self.trace_to_index(t1)\n",
    "        i2 = self.trace_to_index(t2)\n",
    "        return self.matrix[i1][i2]\n",
    "    \n",
    "    # return traces of k nearest neighbors of A\n",
    "    def N_k(self, k, A):\n",
    "        A_variant_index = self.trace_to_index(A)\n",
    "        if A_variant_index in self.Nk_res_dict.keys(): # check result cache\n",
    "            #print(\"N_k cache hit\")\n",
    "            return self.Nk_res_dict[A_variant_index]\n",
    "        else:\n",
    "            idx_sort = np.argsort(self.matrix[A_variant_index]) # indices of neighbors in ascending distance\n",
    "\n",
    "            i = 0\n",
    "            N_k_traces = []\n",
    "            while len(N_k_traces) < k:\n",
    "                N_k_traces.extend(self.index_to_traces(idx_sort[i]))\n",
    "                if A in N_k_traces:\n",
    "                    N_k_traces.remove(A)\n",
    "                i = i + 1\n",
    "                \n",
    "            \n",
    "            self.Nk_res_dict[A_variant_index] = N_k_traces\n",
    "            return N_k_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOF class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LOF:\n",
    "    \n",
    "    def __init__(self, log):\n",
    "        self.dist = Distance(log)\n",
    "        self.dist.calculate()\n",
    "        self.clear_caches()\n",
    "    \n",
    "    def clear_caches(self):\n",
    "        self.dist.clear_caches()\n",
    "        \n",
    "        # result caches\n",
    "        self.kd_res_dict = {}\n",
    "        self.rd_res_dict = {}\n",
    "        self.lof_res_dict = {}\n",
    "        self.lrd_res_dict = {}\n",
    "    \n",
    "    \n",
    "    ## k-distance\n",
    "    def k_distance(self, k, A):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        if A_variant_index in self.kd_res_dict.keys(): # check result cache\n",
    "            #print(\"k_distance cache hit\")\n",
    "            return self.kd_res_dict[A_variant_index]\n",
    "        else:\n",
    "            N_k = self.dist.N_k(k, A)\n",
    "            k_variant_index = self.dist.trace_to_index(N_k[-1])\n",
    "            A_variant_index = self.dist.trace_to_index(A)\n",
    "\n",
    "            res = self.dist.matrix[A_variant_index][k_variant_index] # retrieve distance from k-th nearest neighbor (-1 to offset arraystart, +1 to not include trace itself)\n",
    "            self.kd_res_dict[A_variant_index] = res\n",
    "            return res\n",
    "        \n",
    "    ## reachability distance\n",
    "    def reachability_dist(self, k, A, B):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        B_variant_index = self.dist.trace_to_index(B)\n",
    "        if (A_variant_index, B_variant_index) in self.rd_res_dict.keys(): # check result cache\n",
    "            #print(\"rd cache hit\")\n",
    "            return self.rd_res_dict[(A_variant_index, B_variant_index)]\n",
    "        else:\n",
    "            res = max(self.k_distance(k, B), self.dist.matrix[A_variant_index][B_variant_index])\n",
    "            self.rd_res_dict[(A_variant_index, B_variant_index)] = res\n",
    "            return res\n",
    "    \n",
    "    ## local reachability density\n",
    "    def lrd(self, k, A):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        if A_variant_index in self.lrd_res_dict.keys(): # check result cache\n",
    "            #print(\"lrd cache hit\")\n",
    "            return self.lrd_res_dict[A_variant_index]\n",
    "        else:\n",
    "            \n",
    "            N_k = self.dist.N_k(k, A)            \n",
    "            sum = 0\n",
    "            for b in N_k:\n",
    "                   sum = sum + self.reachability_dist(k, A, b) # sum of rachability distances in k-Neighborhood\n",
    "            \n",
    "            res = 1 / (sum / len(N_k))\n",
    "            self.lrd_res_dict[A_variant_index] = res\n",
    "            return res\n",
    "        \n",
    "    def lof(self, k, A):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        if A_variant_index in self.lof_res_dict.keys(): # check result cache\n",
    "            #print(\"lof cache hit\")\n",
    "            return self.lof_res_dict[A_variant_index]\n",
    "        else:\n",
    "            \n",
    "            N_k = self.dist.N_k(k, A)\n",
    "            sum = 0\n",
    "            for b in N_k:\n",
    "                sum = sum + self.lrd(k, b)\n",
    "\n",
    "            res = sum / (len(N_k) * self.lrd(k, A))\n",
    "            self.lof_res_dict[A_variant_index] = res\n",
    "            return res\n",
    "    \n",
    "    def calculate(self, k):\n",
    "        res = np.array([])\n",
    "        \n",
    "        for a in self.dist.log:\n",
    "            res = np.append(res, self.lof(k, a))\n",
    "            \n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d9e049f6504ee7b3509ba4b387363c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/353 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n"
     ]
    }
   ],
   "source": [
    "path = \"Datasets/BPIC20_sample.xes\"\n",
    "log = xes_importer.apply(path)\n",
    "\n",
    "# generate custom activity classifier\n",
    "try:\n",
    "    \n",
    "    #log, activity_key = insert_classifier.insert_activity_classifier_attribute(self.log, \"Activity classifier\")\n",
    "    for trace in log:\n",
    "        for event in trace:\n",
    "            custom_classifier = \"\"\n",
    "            for activity_classifier in log.classifiers[\"Activity classifier\"]:\n",
    "                custom_classifier = custom_classifier + event[activity_classifier] + \"+\"\n",
    "            custom_classifier = custom_classifier[:-1]\n",
    "            event[\"customClassifier\"] = custom_classifier\n",
    "except:\n",
    "    print(\"foo\")\n",
    "    for trace in log:\n",
    "        for event in trace:\n",
    "            event[\"customClassifier\"] = event[\"concept:name\"]\n",
    "\n",
    "# generate index attribute for each event (later used to fiter)\n",
    "for trace in log:\n",
    "    for i, event in enumerate(trace):\n",
    "        event[\"index\"] = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LOFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 09:29:46.992670\n",
      "max trace length: 35\n",
      "l: 1\n",
      "Number of variants: 21\n",
      "l: 2\n",
      "Number of variants: 49\n",
      "l: 3\n",
      "Number of variants: 107\n",
      "l: 4\n",
      "Number of variants: 184\n",
      "l: 5\n",
      "Number of variants: 248\n",
      "l: 6\n",
      "Number of variants: 290\n",
      "l: 7\n",
      "Number of variants: 314\n",
      "l: 8\n",
      "Number of variants: 322\n",
      "l: 9\n",
      "Number of variants: 325\n",
      "l: 10\n",
      "Number of variants: 326\n",
      "l: 11\n",
      "Number of variants: 327\n",
      "l: 12\n",
      "Number of variants: 327\n",
      "l: 13\n",
      "Number of variants: 327\n",
      "l: 14\n",
      "Number of variants: 327\n",
      "l: 15\n",
      "Number of variants: 327\n",
      "l: 16\n",
      "Number of variants: 327\n",
      "l: 17\n",
      "Number of variants: 327\n",
      "l: 18\n",
      "Number of variants: 327\n",
      "l: 19\n",
      "Number of variants: 327\n",
      "l: 20\n",
      "Number of variants: 327\n",
      "l: 21\n",
      "Number of variants: 327\n",
      "l: 22\n",
      "Number of variants: 327\n",
      "l: 23\n",
      "Number of variants: 327\n",
      "l: 24\n",
      "Number of variants: 327\n",
      "l: 25\n",
      "Number of variants: 327\n",
      "l: 26\n",
      "Number of variants: 327\n",
      "l: 27\n",
      "Number of variants: 327\n",
      "l: 28\n",
      "Number of variants: 327\n",
      "l: 29\n",
      "Number of variants: 327\n",
      "l: 30\n",
      "Number of variants: 327\n",
      "l: 31\n",
      "Number of variants: 327\n",
      "l: 32\n",
      "Number of variants: 327\n",
      "l: 33\n",
      "Number of variants: 327\n",
      "l: 34\n",
      "Number of variants: 327\n",
      "l: 35\n",
      "Number of variants: 327\n",
      "3:32:53.213822\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(start)\n",
    "\n",
    "# find length of longest trace\n",
    "trace_len = [len(i) for i in log]\n",
    "max_trace_len = max(trace_len)\n",
    "print(\"max trace length: \" + str(max_trace_len))\n",
    "\n",
    "res = []\n",
    "\n",
    "for l in range(1, max_trace_len+1): # iterate from 1 to length of longest trace\n",
    "    print(\"l: \" + str(l))\n",
    "    # filter events by attribute \"index\". only events with index between 0 and l are kept\n",
    "    log_tmp = attributes_filter.apply_numeric_events(log, 0, l, \n",
    "                                                     parameters={constants.PARAMETER_CONSTANT_ATTRIBUTE_KEY: \"index\"})\n",
    "    \n",
    "    # run LOF calculation on filtered log\n",
    "    lof = LOF(log_tmp)\n",
    "\n",
    "    k = len(max(lof.dist.variants.values(), key=len)) + 1 # no. traces in largest variant + 1\n",
    "    res_tmp = lof.calculate(k)\n",
    "    res.append(res_tmp)\n",
    "    \n",
    "end = datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mirror results and rotate by 270 degrees\n",
    "res_rot = np.rot90(res[::-1], 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rot = np.genfromtxt(\"res_BPIC20_sample.csv\", delimiter=\",\")\n",
    "res = np.rot90(res_rot)\n",
    "res = res[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 353)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cutoffs for anomaly at each length\n",
    "cutoffs95 = []\n",
    "cutoffs85 = []\n",
    "cutoffs50 = []\n",
    "for l in range(len(res)):\n",
    "    r = []\n",
    "    for t in range(len(res_rot)):\n",
    "        if len(log[t]) >= l + 1:\n",
    "            r.append(res[l][t])\n",
    "    cutoffs50.append(np.percentile(r, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify traces at each point\n",
    "classification = [None] * len(res_rot)\n",
    "\n",
    "for j, trace_res in enumerate(res_rot):\n",
    "    classification_trace = [None] * len(log[j])\n",
    "    for i, r in enumerate(trace_res):\n",
    "        if i < len(log[j]):\n",
    "            if r >= cutoffs50[i]:\n",
    "                classification_trace[i] = \"anomaly\"\n",
    "            else:\n",
    "                classification_trace[i] = \"no anomaly\"\n",
    "    classification[j] = classification_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.23347703,\n",
       " 1.64047624,\n",
       " 1.44341236,\n",
       " 1.36110976,\n",
       " 1.58584883,\n",
       " 1.24288031,\n",
       " 1.16178767,\n",
       " 1.18127806,\n",
       " 1.7242029,\n",
       " 2.29242201,\n",
       " 2.2737838,\n",
       " 2.49398863,\n",
       " 2.37406605,\n",
       " 2.35960501,\n",
       " 2.35566534,\n",
       " 2.59372323,\n",
       " 2.695996015,\n",
       " 2.66267306,\n",
       " 2.79092327,\n",
       " 3.419704205,\n",
       " 3.22642968,\n",
       " 3.3500217,\n",
       " 3.4713991049999997,\n",
       " 3.55468006,\n",
       " 3.71630166,\n",
       " 3.617872785,\n",
       " 3.31841485,\n",
       " 3.6782361,\n",
       " 4.40117114,\n",
       " 4.61862394,\n",
       " 4.79048487,\n",
       " 4.297790035,\n",
       " 4.399185105,\n",
       " 4.612745545,\n",
       " 4.89125937,\n",
       " 4.950587390000001,\n",
       " 5.0318671550000005,\n",
       " 4.24370181,\n",
       " 4.24370181]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoffs50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"res_BPIC20_sample.csv\", res_rot, delimiter=\",\", fmt='%1.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.421878606046619\n",
      "0.578121393953381\n"
     ]
    }
   ],
   "source": [
    "na = 0\n",
    "a = 0\n",
    "for t in classification:\n",
    "    for c in t:\n",
    "        if c == \"no anomaly\":\n",
    "            na = na+1\n",
    "        elif c == \"anomaly\":\n",
    "            a = a+1\n",
    "            \n",
    "t = na + a\n",
    "print(na/t)\n",
    "print(a/t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = []\n",
    "for trace in log:\n",
    "    tlist = []\n",
    "    for i, event in enumerate(trace):\n",
    "        tlist.append(event[\"customClassifier\"])\n",
    "    lists.append(tlist)\n",
    "\n",
    "\n",
    "# split data into training and test\n",
    "lists_train, lists_test, is_anomaly_train, is_anomaly_test = ms.train_test_split(lists, classification, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model\n",
    "- Discrete observations\n",
    "- Two states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pom.HiddenMarkovModel.from_samples(\n",
    "    pom.DiscreteDistribution, \n",
    "    n_components=2,\n",
    "    X=lists_train, \n",
    "    labels=is_anomaly_train,\n",
    "    #state_names=[\"anomaly\", \"no anomaly\", \"unknown\"],\n",
    "    state_names=[\"no anomaly\", \"anomaly\"],\n",
    "    algorithm=\"labeled\")\n",
    "model.bake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : {\n",
       "         \"class\" : \"Distribution\",\n",
       "         \"dtype\" : \"numpy.str_\",\n",
       "         \"name\" : \"DiscreteDistribution\",\n",
       "         \"parameters\" : [\n",
       "             {\n",
       "                 \"Declaration APPROVED by ADMINISTRATION\" : 0.05960648148148148,\n",
       "                 \"Declaration APPROVED by BUDGET OWNER\" : 0.02546296296296296,\n",
       "                 \"Declaration APPROVED by PRE_APPROVER\" : 0.007523148148148148,\n",
       "                 \"Declaration APPROVED by SUPERVISOR\" : 0.003472222222222222,\n",
       "                 \"Declaration FINAL_APPROVED by DIRECTOR\" : 0.0028935185185185184,\n",
       "                 \"Declaration FINAL_APPROVED by SUPERVISOR\" : 0.08043981481481481,\n",
       "                 \"Declaration REJECTED by ADMINISTRATION\" : 0.01678240740740741,\n",
       "                 \"Declaration REJECTED by BUDGET OWNER\" : 0.0005787037037037037,\n",
       "                 \"Declaration REJECTED by DIRECTOR\" : 0.0005787037037037037,\n",
       "                 \"Declaration REJECTED by EMPLOYEE\" : 0.010416666666666666,\n",
       "                 \"Declaration REJECTED by MISSING\" : 0.003472222222222222,\n",
       "                 \"Declaration REJECTED by PRE_APPROVER\" : 0.0028935185185185184,\n",
       "                 \"Declaration REJECTED by SUPERVISOR\" : 0.0028935185185185184,\n",
       "                 \"Declaration SAVED by EMPLOYEE\" : 0.0011574074074074073,\n",
       "                 \"Declaration SUBMITTED by EMPLOYEE\" : 0.08101851851851852,\n",
       "                 \"End trip\" : 0.0775462962962963,\n",
       "                 \"Payment Handled\" : 0.02546296296296296,\n",
       "                 \"Permit APPROVED by ADMINISTRATION\" : 0.05844907407407408,\n",
       "                 \"Permit APPROVED by BUDGET OWNER\" : 0.036458333333333336,\n",
       "                 \"Permit APPROVED by PRE_APPROVER\" : 0.003472222222222222,\n",
       "                 \"Permit APPROVED by SUPERVISOR\" : 0.008680555555555556,\n",
       "                 \"Permit FINAL_APPROVED by DIRECTOR\" : 0.009259259259259259,\n",
       "                 \"Permit FINAL_APPROVED by SUPERVISOR\" : 0.06886574074074074,\n",
       "                 \"Permit REJECTED by ADMINISTRATION\" : 0.003472222222222222,\n",
       "                 \"Permit REJECTED by BUDGET OWNER\" : 0.003472222222222222,\n",
       "                 \"Permit REJECTED by EMPLOYEE\" : 0.005787037037037037,\n",
       "                 \"Permit REJECTED by MISSING\" : 0.0005787037037037037,\n",
       "                 \"Permit REJECTED by SUPERVISOR\" : 0.0005787037037037037,\n",
       "                 \"Permit SAVED by EMPLOYEE\" : 0.0011574074074074073,\n",
       "                 \"Permit SUBMITTED by EMPLOYEE\" : 0.125,\n",
       "                 \"Request For Payment APPROVED by ADMINISTRATION\" : 0.019097222222222224,\n",
       "                 \"Request For Payment APPROVED by BUDGET OWNER\" : 0.011574074074074073,\n",
       "                 \"Request For Payment APPROVED by PRE_APPROVER\" : 0.0023148148148148147,\n",
       "                 \"Request For Payment APPROVED by SUPERVISOR\" : 0.0011574074074074073,\n",
       "                 \"Request For Payment FINAL_APPROVED by DIRECTOR\" : 0.0011574074074074073,\n",
       "                 \"Request For Payment FINAL_APPROVED by SUPERVISOR\" : 0.027777777777777776,\n",
       "                 \"Request For Payment REJECTED by ADMINISTRATION\" : 0.003472222222222222,\n",
       "                 \"Request For Payment REJECTED by EMPLOYEE\" : 0.0028935185185185184,\n",
       "                 \"Request For Payment SUBMITTED by EMPLOYEE\" : 0.027199074074074073,\n",
       "                 \"Request Payment\" : 0.10243055555555555,\n",
       "                 \"Send Reminder\" : 0.007523148148148148,\n",
       "                 \"Start trip\" : 0.06597222222222222\n",
       "             }\n",
       "         ],\n",
       "         \"frozen\" : false\n",
       "     },\n",
       "     \"name\" : \"anomaly\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : {\n",
       "         \"class\" : \"Distribution\",\n",
       "         \"dtype\" : \"numpy.str_\",\n",
       "         \"name\" : \"DiscreteDistribution\",\n",
       "         \"parameters\" : [\n",
       "             {\n",
       "                 \"Declaration APPROVED by ADMINISTRATION\" : 0.06597222222222222,\n",
       "                 \"Declaration APPROVED by BUDGET OWNER\" : 0.01875,\n",
       "                 \"Declaration APPROVED by PRE_APPROVER\" : 0.00625,\n",
       "                 \"Declaration APPROVED by SUPERVISOR\" : 0.001388888888888889,\n",
       "                 \"Declaration FINAL_APPROVED by DIRECTOR\" : 0.001388888888888889,\n",
       "                 \"Declaration FINAL_APPROVED by SUPERVISOR\" : 0.0625,\n",
       "                 \"Declaration REJECTED by ADMINISTRATION\" : 0.02638888888888889,\n",
       "                 \"Declaration REJECTED by BUDGET OWNER\" : 0.0006944444444444445,\n",
       "                 \"Declaration REJECTED by DIRECTOR\" : 0.0,\n",
       "                 \"Declaration REJECTED by EMPLOYEE\" : 0.04375,\n",
       "                 \"Declaration REJECTED by MISSING\" : 0.0,\n",
       "                 \"Declaration REJECTED by PRE_APPROVER\" : 0.0,\n",
       "                 \"Declaration REJECTED by SUPERVISOR\" : 0.0020833333333333333,\n",
       "                 \"Declaration SAVED by EMPLOYEE\" : 0.0,\n",
       "                 \"Declaration SUBMITTED by EMPLOYEE\" : 0.12430555555555556,\n",
       "                 \"End trip\" : 0.09166666666666666,\n",
       "                 \"Payment Handled\" : 0.019444444444444445,\n",
       "                 \"Permit APPROVED by ADMINISTRATION\" : 0.08541666666666667,\n",
       "                 \"Permit APPROVED by BUDGET OWNER\" : 0.009722222222222222,\n",
       "                 \"Permit APPROVED by PRE_APPROVER\" : 0.0125,\n",
       "                 \"Permit APPROVED by SUPERVISOR\" : 0.009027777777777777,\n",
       "                 \"Permit FINAL_APPROVED by DIRECTOR\" : 0.008333333333333333,\n",
       "                 \"Permit FINAL_APPROVED by SUPERVISOR\" : 0.08888888888888889,\n",
       "                 \"Permit REJECTED by ADMINISTRATION\" : 0.0,\n",
       "                 \"Permit REJECTED by BUDGET OWNER\" : 0.0,\n",
       "                 \"Permit REJECTED by EMPLOYEE\" : 0.001388888888888889,\n",
       "                 \"Permit REJECTED by MISSING\" : 0.0,\n",
       "                 \"Permit REJECTED by SUPERVISOR\" : 0.0006944444444444445,\n",
       "                 \"Permit SAVED by EMPLOYEE\" : 0.0,\n",
       "                 \"Permit SUBMITTED by EMPLOYEE\" : 0.05277777777777778,\n",
       "                 \"Request For Payment APPROVED by ADMINISTRATION\" : 0.013194444444444444,\n",
       "                 \"Request For Payment APPROVED by BUDGET OWNER\" : 0.002777777777777778,\n",
       "                 \"Request For Payment APPROVED by PRE_APPROVER\" : 0.0,\n",
       "                 \"Request For Payment APPROVED by SUPERVISOR\" : 0.0,\n",
       "                 \"Request For Payment FINAL_APPROVED by DIRECTOR\" : 0.0,\n",
       "                 \"Request For Payment FINAL_APPROVED by SUPERVISOR\" : 0.008333333333333333,\n",
       "                 \"Request For Payment REJECTED by ADMINISTRATION\" : 0.0020833333333333333,\n",
       "                 \"Request For Payment REJECTED by EMPLOYEE\" : 0.002777777777777778,\n",
       "                 \"Request For Payment SUBMITTED by EMPLOYEE\" : 0.017361111111111112,\n",
       "                 \"Request Payment\" : 0.0798611111111111,\n",
       "                 \"Send Reminder\" : 0.02361111111111111,\n",
       "                 \"Start trip\" : 0.11666666666666667\n",
       "             }\n",
       "         ],\n",
       "         \"frozen\" : false\n",
       "     },\n",
       "     \"name\" : \"no anomaly\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : null,\n",
       "     \"name\" : \"None-start\",\n",
       "     \"weight\" : 1.0\n",
       " },\n",
       " {\n",
       "     \"class\" : \"State\",\n",
       "     \"distribution\" : null,\n",
       "     \"name\" : \"None-end\",\n",
       "     \"weight\" : 1.0\n",
       " }]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73033708, 0.26966292, 0.        , 0.        ],\n",
       "       [0.27944573, 0.72055427, 0.        , 0.        ],\n",
       "       [0.5       , 0.5       , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dense_transition_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive = 0 # anomaly incorrectly detected\n",
    "false_negative = 0 # anomaly incrrectly not detected\n",
    "true_positive = 0 # anomaly correctly detectd\n",
    "true_negative = 0 # anomaly correclty not detected\n",
    "\n",
    "for i, t in enumerate(lists_test):\n",
    "    prediction = model.predict(t)\n",
    "    if prediction[-1] == 0 and is_anomaly_test[i][-1] == \"no anomaly\":\n",
    "        true_negative = true_negative + 1\n",
    "    if prediction[-1] == 0 and is_anomaly_test[i][-1] == \"anomaly\":\n",
    "        false_negative = false_negative + 1\n",
    "    if prediction[-1] == 1 and is_anomaly_test[i][-1] == \"no anomaly\":\n",
    "        false_positive = false_positive + 1\n",
    "    if prediction[-1] == 1 and is_anomaly_test[i][-1] == \"anomaly\":\n",
    "        true_positive = true_positive + 1\n",
    "\n",
    "TPR = true_positive / (true_positive + false_negative)\n",
    "TNR = true_negative / (true_negative + false_positive)\n",
    "        \n",
    "FPR = false_positive / (false_positive + true_negative)\n",
    "FNR = false_negative / (false_negative + true_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anomaly', 'no anomaly', 'anomaly', 'anomaly', 'anomaly', 'no anomaly']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(lists_test[1])\n",
    "is_anomaly_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR\t\t\t28.6%\n",
      "FNR\t\t\t88.9%\n",
      "\n",
      "\n",
      "TNR (sensitivity)\t71.4%\n",
      "TPR (specificity)\t11.1%\n"
     ]
    }
   ],
   "source": [
    "print(\"FPR\\t\\t\\t\" + str(round(FPR * 100, 1)) + \"%\")\n",
    "print(\"FNR\\t\\t\\t\" + str(round(FNR * 100, 1)) + \"%\")\n",
    "print(\"\\n\")\n",
    "print(\"TNR (sensitivity)\\t\" + str(round(TNR * 100, 1)) + \"%\")\n",
    "print(\"TPR (specificity)\\t\" + str(round(TPR * 100, 1)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg: 35\n",
      "pos: 36\n"
     ]
    }
   ],
   "source": [
    "print(\"neg: \" + str(false_positive + true_negative))\n",
    "print(\"pos: \" + str(false_negative + true_positive))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
