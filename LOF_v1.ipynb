{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import all necessary libraries ##\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "#########################\n",
    "\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.filtering.log.attributes import attributes_filter\n",
    "from pm4py.algo.filtering.log.variants import variants_filter\n",
    "\n",
    "#########################\n",
    "\n",
    "import distance\n",
    "\n",
    "from similarity.levenshtein import Levenshtein\n",
    "levenshtein = Levenshtein()\n",
    "\n",
    "from similarity.damerau import Damerau\n",
    "damerau = Damerau()\n",
    "\n",
    "from pyjarowinkler import distance as jwdistance\n",
    "from similarity.jarowinkler import JaroWinkler\n",
    "jarowinkler = JaroWinkler()\n",
    "\n",
    "from similarity.weighted_levenshtein import WeightedLevenshtein\n",
    "from similarity.weighted_levenshtein import CharacterSubstitutionInterface\n",
    "import math\n",
    "class CharacterSubstitution(CharacterSubstitutionInterface):\n",
    "    def cost(self, c0, c1):\n",
    "        return math.inf # assign inifte weight to all substitutions\n",
    "levenshtein2 = WeightedLevenshtein(CharacterSubstitution())\n",
    "\n",
    "#########################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distance:\n",
    "    \n",
    "    ### SETUP ###\n",
    "    \n",
    "    ## load dataset, generate mapping and generate strings\n",
    "    def __init__(self, path):\n",
    "        self.strings = []\n",
    "        self.matrix = []\n",
    "        self.transl = {}\n",
    "        self.variant_to_Vindex = {}\n",
    "        self.index_to_variant = []\n",
    "        \n",
    "        self.log = xes_importer.apply(path) # adjust for local file location       \n",
    "        \n",
    "        self.clear_caches()\n",
    "        \n",
    "        self.gen_trace_to_Tindex()\n",
    "        \n",
    "        self.gen_mapping()\n",
    "        self.gen_variant_strings()        \n",
    "    \n",
    "    def clear_caches(self):\n",
    "        self.Nk_res_dict = {} # N_k result cache\n",
    "    \n",
    "    ## generate mapping from activity to char\n",
    "    def gen_mapping(self):\n",
    "        ## generate mapping from activities to chars ##\n",
    "        # TODO read Activity classifier for correct naming of activities\n",
    "        activities = list(attributes_filter.get_attribute_values(self.log, \"concept:name\").keys())\n",
    "        #activities2 = list(attributes_filter.get_attribute_values(self.log, \"lifecycle:transition\").keys())\n",
    "        #activities = [i + \"-\" + j for i, j in zip(activities2, activities2)]\n",
    "        for i, a in enumerate(activities):\n",
    "            self.transl[a] = chr(i+1)\n",
    "\n",
    "    def gen_trace_to_Tindex(self):\n",
    "        self.trace_to_Tindex = {}\n",
    "        for i, t in enumerate(self.log):\n",
    "            self.trace_to_Tindex[t] = i\n",
    "            \n",
    "            \n",
    "    ## generate strings for all variants\n",
    "    def gen_variant_strings(self):\n",
    "        self.variants = variants_filter.get_variants(self.log) # all variants as dictionary\n",
    "        variant_strings = list(self.variants.keys()) # variants as strings\n",
    "        self.variant_to_index = {} # dictionary to translate variant to index in list for later lookup of traces\n",
    "        \n",
    "        for i, v in enumerate(variant_strings):\n",
    "            string = \"\"\n",
    "            for e in v.split(\",\"):\n",
    "                string = string + self.transl[e] \n",
    "            \n",
    "            #self.strings.append(list_to_string(v.split(\",\")))\n",
    "            self.strings.append(string)\n",
    "            \n",
    "            self.variant_to_index[v] = i\n",
    "            self.index_to_variant.append(v)\n",
    "            \n",
    "        print(\"Number of variants: \" + str(len(self.strings)))\n",
    "    \n",
    "    ### CALCULATION ###\n",
    "    \n",
    "    ## calculate distance matrix\n",
    "    def calculate(self):\n",
    "        n = len(self.strings)\n",
    "        self.matrix = np.full((n, n), 0, dtype = np.uint8)\n",
    "\n",
    "        for i, x in enumerate(self.strings):\n",
    "            for j, y in enumerate(self.strings):\n",
    "                if j >= i: # only calculate upper right triangle of matrix\n",
    "                    #dist = distance.hamming(x, y)\n",
    "                    dist = levenshtein.distance(x, y)\n",
    "                    #dist = levenshtein2.distance(x, y)\n",
    "                    #dist = damerau.distance(x, y)\n",
    "                    #dist = (1- jarowinkler.similarity(x, y))*255\n",
    "                    #print(dist)\n",
    "                    self.matrix[i][j] = dist\n",
    "\n",
    "        # mirror upper right triangle of matrix by adding the transposition\n",
    "        self.matrix = self.matrix + self.matrix.T\n",
    "\n",
    "        return self.matrix\n",
    "    \n",
    "    ### RETRIEVAL ###\n",
    "    \n",
    "    ## translate trace to its corresponding matrix index\n",
    "    def trace_to_index(self, trace):\n",
    "        # convert trace to string tion of variant (concept:name separated by commas)\n",
    "        trace_string = \"\"\n",
    "        for e in trace:\n",
    "            trace_string = trace_string + e[\"concept:name\"] + \",\"\n",
    "        trace_string = trace_string[:-1] # remove last comma\n",
    "\n",
    "        return self.variant_to_index[trace_string]\n",
    "    \n",
    "    ## translate matrix (variant) index to trace indices\n",
    "    def index_to_traces(self, i):\n",
    "        variant_string = self.index_to_variant[i]\n",
    "        traces = self.variants[variant_string] # retrieve traces from variant dictionary\n",
    "        filtered_variants = {variant_string: traces} # generate new variants dictionary with only one variant\n",
    "        \n",
    "        filtered_log = variants_filter.apply(self.log, filtered_variants)\n",
    "        traces = []\n",
    "        for t in filtered_log:\n",
    "            traces.append(t)\n",
    "        \n",
    "        return traces\n",
    "        \n",
    "    \n",
    "    ## retrieve distance of two traces from matrix\n",
    "    def dist(self, t1, t2):\n",
    "        i1 = self.trace_to_index(t1)\n",
    "        i2 = self.trace_to_index(t2)\n",
    "        return self.matrix[i1][i2]\n",
    "    \n",
    "    # return traces of k nearest neighbors of A\n",
    "    def N_k(self, k, A):\n",
    "        A_variant_index = self.trace_to_index(A)\n",
    "        if A_variant_index in self.Nk_res_dict.keys(): # check result cache\n",
    "            #print(\"N_k cache hit\")\n",
    "            return self.Nk_res_dict[A_variant_index]\n",
    "        else:\n",
    "            idx_sort = np.argsort(self.matrix[A_variant_index]) # indices of neighbors in ascending distance\n",
    "\n",
    "            i = 0\n",
    "            N_k_traces = []\n",
    "            while len(N_k_traces) < k:\n",
    "                N_k_traces.extend(self.index_to_traces(idx_sort[i]))\n",
    "                if A in N_k_traces:\n",
    "                    N_k_traces.remove(A)\n",
    "                i = i + 1\n",
    "            \n",
    "            self.Nk_res_dict[A_variant_index] = N_k_traces\n",
    "            return N_k_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOF class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LOF:\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.dist = Distance(path)\n",
    "        self.dist.calculate()\n",
    "        self.clear_caches()\n",
    "    \n",
    "    def clear_caches(self):\n",
    "        self.dist.clear_caches()\n",
    "        \n",
    "        # result caches\n",
    "        self.kd_res_dict = {}\n",
    "        self.rd_res_dict = {}\n",
    "        self.lof_res_dict = {}\n",
    "        self.lrd_res_dict = {}\n",
    "    \n",
    "    \n",
    "    ## k-distance\n",
    "    def k_distance(self, k, A):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        if A_variant_index in self.kd_res_dict.keys(): # check result cache\n",
    "            #print(\"k_distance cache hit\")\n",
    "            return self.kd_res_dict[A_variant_index]\n",
    "        else:\n",
    "            N_k = self.dist.N_k(k, A)\n",
    "            k_variant_index = self.dist.trace_to_index(N_k[-1])\n",
    "            A_variant_index = self.dist.trace_to_index(A)\n",
    "\n",
    "            res = self.dist.matrix[A_variant_index][k_variant_index] # retrieve distance from k-th nearest neighbor (-1 to offset arraystart, +1 to not include trace itself)\n",
    "            self.kd_res_dict[A_variant_index] = res\n",
    "            return res\n",
    "        \n",
    "    ## reachability distance\n",
    "    def reachability_dist(self, k, A, B):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        B_variant_index = self.dist.trace_to_index(B)\n",
    "        if (A_variant_index, B_variant_index) in self.rd_res_dict.keys(): # check result cache\n",
    "            #print(\"rd cache hit\")\n",
    "            return self.rd_res_dict[(A_variant_index, B_variant_index)]\n",
    "        else:\n",
    "            res = max(self.k_distance(k, B), self.dist.matrix[A_variant_index][B_variant_index])\n",
    "            self.rd_res_dict[(A_variant_index, B_variant_index)] = res\n",
    "            return res\n",
    "    \n",
    "    ## local reachability density\n",
    "    def lrd(self, k, A):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        if A_variant_index in self.lrd_res_dict.keys(): # check result cache\n",
    "            #print(\"lrd cache hit\")\n",
    "            return self.lrd_res_dict[A_variant_index]\n",
    "        else:\n",
    "            \n",
    "            N_k = self.dist.N_k(k, A)            \n",
    "            sum = 0\n",
    "            for b in N_k:\n",
    "                   sum = sum + self.reachability_dist(k, A, b) # sum of rachability distances in k-Neighborhood\n",
    "            \n",
    "            res = 1 / (sum / len(N_k))\n",
    "            self.lrd_res_dict[A_variant_index] = res\n",
    "            return res\n",
    "        \n",
    "    def lof(self, k, A):\n",
    "        A_variant_index = self.dist.trace_to_index(A)\n",
    "        if A_variant_index in self.lof_res_dict.keys(): # check result cache\n",
    "            #print(\"lof cache hit\")\n",
    "            return self.lof_res_dict[A_variant_index]\n",
    "        else:\n",
    "            \n",
    "            N_k = self.dist.N_k(k, A)\n",
    "            sum = 0\n",
    "            for b in N_k:\n",
    "                sum = sum + self.lrd(k, b)\n",
    "\n",
    "            res = sum / (len(N_k) * self.lrd(k, A))\n",
    "            self.lof_res_dict[A_variant_index] = res\n",
    "            return res\n",
    "    \n",
    "    def calculate(self, k):\n",
    "        res = np.array([])\n",
    "        for a in self.dist.log:\n",
    "            res = np.append(res, self.lof(k, a))\n",
    "            \n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9474acbd34b48b98d58ebe53b2109ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/1487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variants: 183\n"
     ]
    }
   ],
   "source": [
    "path = \"Datasets/BPIC13.xes\"\n",
    "lof = LOF(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-05 12:10:47.746080\n",
      "0:01:39.462414\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(start)\n",
    "\n",
    "k = len(max(lof.dist.variants.values(), key=len)) + 1 # no. traces in largest variant + 1\n",
    "lof.clear_caches()\n",
    "#print(lof.lof(k, lof.dist.log[0]))\n",
    "res = lof.calculate(k)\n",
    "\n",
    "end = datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.112\tQueued,Accepted,Accepted,Accepted,Completed\n",
      "1.155\tAccepted,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.079\tAccepted,Accepted,Accepted,Accepted,Completed\n",
      "1.079\tAccepted,Accepted,Accepted,Accepted,Completed\n",
      "1.277\tAccepted,Accepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.345\tAccepted,Accepted,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.277\tAccepted,Accepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.599\tAccepted,Accepted,Accepted,Queued,Accepted,Queued,Accepted,Completed\n",
      "1.079\tAccepted,Accepted,Accepted,Accepted,Completed\n",
      "1.013\tAccepted,Accepted,Completed\n",
      "1.528\tAccepted,Queued,Accepted,Queued,Accepted,Accepted,Queued,Accepted,Completed\n",
      "1.0\tAccepted,Unmatched,Completed\n",
      "1.814\tQueued,Accepted,Accepted,Queued,Queued,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.0\tAccepted,Unmatched,Completed\n",
      "1.0\tAccepted,Completed\n",
      "1.013\tAccepted,Accepted,Completed\n",
      "1.739\tAccepted,Accepted,Accepted,Accepted,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.079\tAccepted,Accepted,Accepted,Accepted,Completed\n",
      "1.818\tAccepted,Unmatched,Queued,Accepted,Accepted,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.554\tAccepted,Accepted,Queued,Accepted,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.181\tAccepted,Accepted,Queued,Accepted,Accepted,Completed\n",
      "1.345\tAccepted,Accepted,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.164\tQueued,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "2.648\tAccepted,Accepted,Queued,Accepted,Accepted,Accepted,Accepted,Queued,Accepted,Queued,Accepted,Accepted,Completed\n",
      "1.433\tAccepted,Queued,Accepted,Unmatched,Completed\n",
      "1.095\tUnmatched,Accepted,Accepted,Completed\n",
      "1.013\tAccepted,Accepted,Completed\n",
      "1.013\tAccepted,Accepted,Completed\n",
      "1.013\tAccepted,Accepted,Completed\n",
      "1.0\tAccepted,Unmatched,Completed\n",
      "1.013\tAccepted,Accepted,Completed\n",
      "1.0\tAccepted,Completed\n",
      "1.345\tAccepted,Accepted,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.546\tAccepted,Queued,Queued,Accepted,Completed\n",
      "1.013\tAccepted,Accepted,Completed\n",
      "1.155\tAccepted,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.064\tAccepted,Accepted,Accepted,Completed\n",
      "1.0\tAccepted,Completed\n",
      "1.013\tAccepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.013\tAccepted,Accepted,Completed\n",
      "1.413\tQueued,Accepted,Queued,Accepted,Completed\n",
      "1.079\tAccepted,Accepted,Accepted,Accepted,Completed\n",
      "2.084\tAccepted,Accepted,Accepted,Queued,Accepted,Accepted,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.064\tAccepted,Accepted,Accepted,Completed\n",
      "1.064\tAccepted,Accepted,Accepted,Completed\n",
      "1.506\tAccepted,Accepted,Queued,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.829\tAccepted,Queued,Accepted,Accepted,Accepted,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.013\tAccepted,Accepted,Completed\n",
      "1.161\tAccepted,Unmatched,Accepted,Accepted,Accepted,Completed\n",
      "1.013\tAccepted,Accepted,Completed\n",
      "1.079\tAccepted,Accepted,Accepted,Accepted,Completed\n",
      "1.0\tAccepted,Completed\n",
      "1.785\tAccepted,Accepted,Queued,Accepted,Queued,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.277\tAccepted,Queued,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.064\tAccepted,Accepted,Accepted,Completed\n",
      "1.013\tAccepted,Accepted,Completed\n",
      "1.013\tAccepted,Accepted,Completed\n",
      "1.0\tAccepted,Completed\n",
      "1.181\tAccepted,Accepted,Queued,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.277\tAccepted,Accepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.064\tAccepted,Accepted,Accepted,Completed\n",
      "1.277\tAccepted,Accepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.807\tAccepted,Accepted,Queued,Accepted,Unmatched,Completed\n",
      "1.082\tAccepted,Unmatched,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.013\tAccepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "2.294\tAccepted,Accepted,Accepted,Accepted,Accepted,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.345\tAccepted,Accepted,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.476\tAccepted,Queued,Accepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.064\tAccepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "2.383\tAccepted,Queued,Accepted,Queued,Queued,Accepted,Accepted,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "2.656\tAccepted,Queued,Accepted,Accepted,Queued,Accepted,Accepted,Accepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.155\tAccepted,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.277\tAccepted,Queued,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "1.474\tAccepted,Queued,Accepted,Accepted,Queued,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.0\tAccepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.509\tAccepted,Unmatched,Queued,Accepted,Accepted,Accepted,Accepted,Completed\n",
      "2.071\tAccepted,Queued,Accepted,Accepted,Accepted,Accepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.506\tAccepted,Accepted,Accepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.515\tQueued,Accepted,Queued,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n",
      "1.194\tAccepted,Queued,Accepted,Accepted,Accepted,Completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for t in range(100):\n",
    "    t_string = \"\"\n",
    "    for e in lof.dist.log[t]:\n",
    "        t_string = t_string + e[\"concept:name\"] + \",\"\n",
    "    t_string = t_string[:-1]\n",
    "    \n",
    "    print(str(round(res[t], 3)) + \"\\t\" + t_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
